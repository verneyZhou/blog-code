---
title: 面试题收集2024
date: 2024-01-31 11:31:46
permalink: false
article: false
categories: 
  - null
tags: 
  - null
---


# 面试题收集2024



## HTML/CSS部分


### css盒模型

默认标准盒模型（content-box）：width = content

ie盒模型（border-box）: width = content + padding + border



### BFC

块格式上下文，是一块独立的渲染区域，内部元素不会影响外部的元素。

BFC是浏览器中的一个独立渲染区域，拥有一套渲染规则，决定了其子元素如何定位以及与其他元素的相互关系和作用。可以把BFC理解为一个封闭的大箱子，箱子内部的元素无论如何翻江倒海，都不会影响到外部。反之亦然，计算BFC的高度时，浮动元素也参与计算。

哪些元素会产生BFC：
- 根元素。
- float属性不为none。
- position为absolute或fixed。
- display为inline-block, table-cell, table-caption, flex, inline-flex。
- overflow不为visible。


BFC有以下应用场景：
- `清除盒子垂直方向上外边距合并`：给其中一个盒子再包裹一个盒子父元素，并触发其BFC功能（例如添加overflow:hidden;）
- `解决父元素高度塌陷的问题`：当子元素设置成浮动元素时，会产生父元素高度塌陷的问题。可以给父元素设置overflow:hidden;来产生BFC，从而解决这个问题。



### flex:1

`flex-grow: 1`：设置子元素的放大比例，决定了子元素在剩余空间中的占比，默认为`0`, 即元素不会放大来占用多余空间。当为 `1` 时，表示子元素会根据剩余空间等比例地放大，使得所有子元素填满父容器的剩余空间。

`flex-shrink: 1`: 设置子元素的收缩比例，当容器空间不足时，元素会按照其flex-shrink值与其他元素的比例来缩小。为 1表示子元素会按照等比例收缩。

`flex-basis: 0%`: 设置子元素的基础尺寸(设置子项的占用空间),默认为`auto`, 意味着元素的大小会根据其内容自动计算；`0%`表示子元素的尺寸会尽可能地被拉伸以填充剩余空间。

这样设置后，子元素会根据剩余空间等比例地放大，并在空间不足时按照等比例收缩，同时初始尺寸为 0%，以适应父容器的大小。



### flex-direction: column; align-item: center; 是怎么布局

- `flex-direction: column`规定子元素排列方向是从上往下垂直排列（主轴是垂直方向）

- `align-item: center`: 表示子元素水平方向（交叉轴，因为主轴是垂直方向）居中对齐



### 回流（重排）与重绘


`回流（reflow）`是更明显的一种改变，可以理解为渲染树需要重新计算。（当render树中因为大小边距等问题发生改变而需要重建的过程就是回流）

因为只要不是改变物理的位置、尺寸、显示，就不会引起回流。


`重绘（repaints）`是一个元素外观的改变所触发的浏览器行为，（也就是当元素的一部分属性发生变化，如外观背景色不会引起布局变化而需要重新渲染的过程就是重绘）


`v-if`通过增删dom节点实现显隐，`v-show`通过设置`display`属性实现dom显隐；两个都会触发回流和重绘；`visibility`属性不会触发重排，会触发重绘。


会触发回流的属性：`offsetTop、offsetLeft、 offsetWidth、offsetHeight、scrollTop、scrollLeft、scrollWidth、scrollHeight、clientTop、clientLeft、clientWidth、clientHeight`, 需要通过即时计算得到。因此浏览器为了获取这些值，也会进行回流; 除此还包括getComputedStyle方法，原理是一样的.



触发重绘：颜色改变，透明度改变，元素的border-radius、visibility、box-shadow等属性发生变化, 不改变大小位置的改变

`transform、opacity、filters`这些动画不会引起回流重绘


避免不必要的回流和重绘: `避免频繁操作样式、避免使用table布局、避免频繁操作DOM、尽量使用CSS3动画代替JS动画`等。


### meta 标签

[meta 标签](https://juejin.cn/post/6987919006468407309)

head标签用于定于文档头部信息，它是所有头部元素的容器。head中的元素可以引用脚本、指示浏览器在哪里找到样式表、提供元信息等等: 

`base, link, meta, script, style, 以及 title`


meta: `<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">`

1. `http-equiv` 属性: 一般设置的都是与http请求头相关的信息，设置的值会关联到http头部。也就是说浏览器在请求服务器获取html的时候，服务器会将html中设置的meta放在响应头中返回给浏览器: 

`<meta http-equiv="content-type" content="text/html charset=utf8">` 用来声明文档类型、设字符集，目前content-type只能在html文档中使用; 

`<meta http-equiv="expires" content="31 Dec 2021">` 用于设置浏览器的过期时间, 其实就是响应头中的expires属性。

`<meta http-equiv="pragma" content="no-cache">`: 禁止浏览器从本地计算机的缓存中访问页面的内容



2. `name`属性：主要用于描述网页，与对应的content中的内容主要是便于搜索引擎查找信息和分类信息用的, 用法与http-equiv相同，name设置属性名，content设置属性值:

`<meta name="author" content="aaa@mail.abc.com">`、`<meta name="keywords" content="Hello world">`

`<meta name="robots" content="all">`: 告诉搜索引擎机器人抓取哪些页面, all：文件将被检索，且页面上的链接可以被查询； none：文件将不被检索，且页面上的链接不可以被查询；




### 解决移动端 Retina 屏 1px 像素问题

1. 伪元素 + `transform` 实现: 伪元素 `::after` 或 `::before` 是独立于当前元素，可以单独对其缩放而不影响元素本身的缩放; 基于 `media` 查询判断不同的设备像素比对线条进行缩放
2. media媒体查询设备像素比
3. 新项目可以尝试使用 `viewport + rem` 方案


[最后一次探究1px](https://juejin.cn/post/6870691193353666568)




### 移动端rem、px 转换逻辑？

rem是指根元素(root element html) 的字体大小

rootFontSize = screenWidth * DPR / baseValue；

1rem等于75px,以width为750px的设计稿为标准，当width为750px时，根元素font-size为37.5px （375 * 1 / 10）

比如p标签内设置font-size为24px：
1. 打包的时候转为rem,24 / 75 = 0.32rem;
2. 由lib-flexible动态计算得根元素font-size为37.5px，即该宽度下，1rem为37.5px;
3. 计算p标签内字体展示大小：0.32 * 37.5 = 12px



### svg 与 canvas 有什么区别？

SVG和Canvas都是用于在Web页面上绘制图形的技术

1. `图像类型`：SVG是基`于XML的矢量图形语言`，而Canvas则是基于`HTML5的位图图形绘制API`。这意味着SVG绘制的图形是矢量图，无论放大多少倍都不会失真，而Canvas绘制的图形是像素图，放大后会出现锯齿状边缘。

2. `操作方式`：SVG中的每个图形都是DOM节点，可以通过JavaScript直接操作这些节点，改变其颜色、形状等属性。而Canvas则是通过JavaScript在画布上绘制图形，一旦绘制完成，就不能直接修改图形本身，只能通过清除整个画布然后重新绘制来实现修改。

3. `性能`：Canvas在绘制大量图形或进行频繁更新时性能更好，因为`它基于像素渲染`，可以直接在内存中操作。而`SVG由于是基于DOM`的，所以在处理大量图形或复杂交互时可能会显得较慢。

4. `兼容性`：SVG和Canvas都只能在IE8（不包含IE8）以上版本的浏览器中运行。不过，Canvas在移动端的兼容性更好。

5. `颜色支持`：Canvas支持的颜色比SVG更多，因此更适合绘制色彩丰富的图像



### jpg, png, webp 的区别？

- JPG（JPEG）格式是一种`有损压缩格式`，它支持16百万种颜色，适合显示真实摄影图像; 保存图像时会损失一些细节, 压缩会导致失真。此外，JPG格式不支持透明度。

- PNG格式是一种`无损压缩格式`，它支持透明度，可创建带有透明背景的图像, PNG图像的优点是图像质量不会受到损失，但文件大小相对较大，不如JPG和WebP压缩得那么好

- WebP格式是一种新的图像格式，由Google开发。它支持有损和无损压缩，具有更高的压缩比，同时保留较好的图像质量。WebP图像支持透明度，可用于制作带有透明背景的图像，还支持动画。然而，WebP尚未被所有设备和软件广泛支持，但在现代浏览器中得到了很好的支持。图片压缩内存较小



### 伪类选择器有哪些？

`:hover, :active, :focus, :visited, :link, :disabeld, :nth-child()`

伪元素：`::before, ::after, ::selection`



### 页面渲染流程？

1. `解析html/css`: 解析HTML,生成HTMLDOM树；同时解析css，生成CSSDOM树；
2. `构建渲染树`：在DOM树和CSSOM树都构建完成后，浏览器会将它们合并成一个渲染树；
3. `布局`：在渲染树构建完成后，浏览器会开始布局过程。这个过程主要是计算每个元素在屏幕上的确切位置和大小。这通常包括确定元素的盒模型（即元素的边距、边框、填充和内容区域的大小和位置）以及元素之间的相对位置等。
4. `绘制`：最后，浏览器会根据计算出的布局信息，将每个元素绘制到屏幕上。这个过程通常包括填充元素的背景、边框和颜色等，并显示文本和图像等内容。


css加载不会阻塞DOM树的解析，css加载会阻塞DOM树的渲染，css加载会阻塞后面js语句的执行。


### DOMContentLoaded在什么时候触发？

DOMContentLoaded事件在文档对象模型`（DOM）完全加载和解析完成后触发，无需等待样式表、图像和子框架的完全加载`。换句话说，当HTML解析完毕，DOM树构建完毕，但图片等其他资源还没有加载完成时，就会触发DOMContentLoaded事件。

这个事件与window.onload事件相似，但有一个主要区别：`window.onload事件必须等到整个页面及所有依赖资源如样式表和图片都已完成加载后才会触发`。因此，如果页面的图片很多，从用户访问到window.onload触发可能需要较长的时间，这会影响用户的体验。

DOMContentLoaded事件在DOM树构建完成后就会触发，因此可以更早地执行脚本和绑定事件到元素，而无需等待所有图片等资源加载完成。


> js会阻塞DOM解析，DOMContentLoaded是在DOM解析完成后才触发。因此，当css后面有js的时候，css会阻塞js运行，而js会阻塞DOM解析，从而导致DOMContentLoaded必须等到css以及css后面的js执行完成后，才会触发。而当css后面没有js的时候，由于css不阻塞DOM的解析，因此DOMContentLoaded不会等待css的加载。






## JS部分



### 原型


- **什么是原型？**

> 我们创建的每一个构造函数都会有一个 `prototype` 属性，这个属性指向一个对象，这个对象包含该构造函数创建的所有实例能够共享的属性和方法；这个对象就是原型，也叫做原型对象。


- **什么是原型链？**

> js的每个对象都会从它的原型对象那里继承一些属性，而原型对象也会有自己的原型；这样每个对象沿着它的原型一层层往上面查找形成的链式结构，就称为原型链，一般原型链找到最顶层`Object.prototype`就停止查找了。js对象间就是通过原型链产生关联, 实现继承。

`__proto__`查找: person ===> Person.prototype ===> Object.prototype ===> null


`Object.__proto__ === Function.prototype`, `Function.__proto__ === Function.prototype`
> 所有的构造函数都是对象，都是Function的一个实例；而原生构造函数Function也是一个对象。





### 进程与线程

进程：cpu分配资源的最小单位。
> 电脑打开一个软件产生一个或多个进程，每个进程之间是相互独立的，CPU使用 `时间片轮转调度算法` 来实现同时运行多个进程。

线程：程序执行的最小单位。

1. 一个进程可以有多个线程，一个进程中只有一个**执行流**称作单线程；
2. 进程之间相互独立，但同一进程下的各个线程间共享程序的内存空间；


Chrome：每打开一个Tab页就会产生一个进程。

**渲染进程：页面的渲染，JS的执行，事件的循环，都在渲染进程内执行。**
1. GPU的渲染线程：负责渲染浏览器界面，解析HTML, 布局和绘制；与JS的执行线程互斥，GUI更新会被保存在一个队列中等到JS引擎空闲时立即被执行
2. **JS引擎线程**：负责处理js脚本（v8引擎）, 浏览器同时只能有一个JS引擎线程在运行JS程序，所以js是单线程运行的。
    - `defer`: 要等到整个页面在内存中正常渲染结束（DOM 结构完全生成，以及其他脚本执行完成），才会执行；
    - `async`: js加载时不阻塞渲染，一旦下载完，渲染引擎就会中断渲染，执行这个脚本以后，再继续渲染；
3. 事件触发线程：属于浏览器而不是JS引擎，用来控制事件循环，并且管理着一个事件队列(task queue)
4. 定时器触发线程：setInterval与setTimeout
5. Http异步请求线程： ajax



`同步任务 -> 微任务 -> GUI渲染 -> 宏任务 -> ...`



- **JS为什么是单线程？**

> JavaScript之所以是单线程的，是因为它的设计初衷是为了简化并发问题、避免浏览器环境下的限制，并且通过事件循环机制实现异步编程。

1. 单线程模型使得 JavaScript 的设计更为简单。开发者不需要考虑多线程编程中常见的复杂问题，如线程间的同步、互斥、死锁等。
2. JavaScript 最初是为浏览器环境设计的，其`主要任务是与用户交互和操作 DOM`。在这样的环境中，多线程可能会导致一系列问题，如 UI 渲染不一致、线程安全问题等。如果js被设计了多线程，如果有一个线程要修改一个dom元素，另一个线程要删除这个dom元素，此时浏览器就会一脸茫然，不知所措。所以，为了避免复杂性，从一诞生，JavaScript就是单线程。
3. JavaScript的单线程设计是建立在事件循环机制之上的。事件循环是JavaScript实现异步编程的关键，它使得JavaScript可以在单线程中实现非阻塞的I/O操作，从而实现异步编程。
4. 为了利用多核CPU的计算能力，HTML5提出`Web Worker`标准，允许JavaScript脚本创建多个线程，但是`子线程完全受主线程控制，且不得操作DOM`。所以，这个新标准并没有改变JavaScript单线程的本质。




### Event Loop

1. 整体的js脚本是第一个宏任务，它开始执行时，会把所有代码分为同步任务和异步任务；同步任务直接进行主线程执行，异步任务再分为宏任务和微任务，分别将各自的回调事件放置在任务队列中等到调用；
2. 当调用栈上的同步任务执行完成后，先检查微任务队列，有则执行，没有则将宏任务队列的第一个宏任务添加到主线程执行栈上，开始执行；
3. 重复上述流程；


`macrotasks`: script(整体代码)、setTimeout、setInterval、setImmediate（node独有）、I/O、UI rendering（浏览器独有）、requestAnimationFrame (opens new window)（浏览器独有）

`microtasks`: process.nextTick（node独有）、Promises、Object.observe(废弃)、MutationObserver


### node.js的运行机制

node中的Event Loop跟浏览器中执行流程大致类似，也是`同步任务 》 微任务 》 宏任务`; 

但node中的宏队列不像浏览器中只有一个宏队列，而是细分出4个阶段的宏队列：`Timers Queue、 IO Callbacks Queue、Check Queue、Close Callbacks Queue`；同样微队列也是细分成2个阶段的微队列：`Next Tick Queue、Other Micro Queue`

1. 执行全局Script的同步代码
2. 执行microtask微任务，先执行所有Next Tick Queue中的所有任务，再执行Other Microtask Queue中的所有任务
3. 开始执行macrotask宏任务，共6个阶段，从第1个阶段开始执行相应每一个阶段macrotask中的所有任务，注意，**这里“所有任务”是指每个阶段宏任务队列的所有任务，在浏览器的Event Loop中是只取宏队列的第一个任务出来执行，每一个阶段的macrotask任务执行完毕后，开始执行微任务**，也就是步骤2
4. `Timers Queue -> 步骤2 -> I/O Queue -> 步骤2 -> Check Queue -> 步骤2 -> Close Callback Queue -> 步骤2 -> Timers Queue ......`
5. 这就是Node的Event Loop








### js执行流程


js执行主要分为分析（预编译）和执行两个阶段。


**作用域链**
> 当查找变量的时候，会先从当前上下文的变量对象中查找，如果没有找到，就会从父级执行上下文的变量对象中查找，一直找到全局上下文的变量对象，也就是全局对象。这样由多个执行上下文的变量对象构成的链表就叫做作用域链。


`分析`:
1. 当js在读取js脚本时，会首先创建一个**全局执行上下文**，并将该上下文push到**js调用栈**中；如果有函数调用时，会创建新的**函数执行上下文**push到调用栈；每调用一个函数，js就会把该函数添加进调用栈并开始执行。
> js是一门单线程语言：同一时间只能做一件事；Js 有一个`主线程（main thread）`和`call-stack 调用栈(执行栈)`，所有的任务都会被放到调用栈等待主线程执行。

2. 在创建上下文时，这时候还没有执行代码，主要初始化三个属性：`变量对象（VO）、作用域链、this指向`
    - 变量对象：上下文中定义的变量和函数的声明；进行初始化，变量不会赋值只会先声明，等到后面执行时再赋值；函数会直接声明+赋值；这个阶段的变量对象不可以访问；

`执行`:
1. 当js进入函数上下文开始执行时，变量对象会激活成活动对象（AO）,这时它上面的属性才可以被访问；这时开始修改AO的属性值；
2. 当函数执行完毕，就会将该上下文从调用栈中弹出；执行下一个上下文；






### 什么是闭包？

> 闭包主要是指那些能够访问到自由变量的函数；自由变量是指能够在函数中使用，但既不是函数参数也不是函数局部变量的变量。

1. 在代码中引用了自由变量
2. **自由变量的上下文已经销毁，但还是能引用它**
> 这是因为当在一个函数上下文中查找变量时，会沿着**作用域链**网上查找；当函数引用自由变量时，即使这个自由变量的上下文被销毁了，但是js依然会让这个上下文的AO活在内存中；函数依然可以通过它的作用域链找到它，正是因为JS做到了这一点，从而实现了闭包这个概念。



优点：闭包是一种**保护私有变量**的机制，在函数执行时形成私有的作用域，保护里面的私有变量不受外界干扰。

缺点：创建闭包必须维护额外的作用域，过度使用它们可能会占用大量内存，比较常见的问题就是造成**内存泄露**



- `IIFE` 可以模拟块级作用域，目的是为了隔离作用域，防止污染全局命名空间。
> 可以减少闭包占用的内存问题，因为没有指向匿名函数的引用。只要函数执行完毕，就可以立即销毁其作用域链了。



``` js
var fn = [];

for (var i = 0; i < 3; i++) {
  fn[i] = function () {
    console.log(i);
  };
}
fn[0](); // 3： 当执行fn[0]函数的时候，fn[0]函数的作用域链: [AO, globalContext.VO] 中的AO没有i值，所以往上找到全局变量i=3
fn[1](); // 3
fn[2](); // 3


////// 改成闭包
for(var i = 0; i < 3; i ++) {
    fn[i] = (function(j) { // 等于匿名自执行函数
        return function() { // 返回一个闭包
            console.log(j);
        }
    })(i)
}
fn[0](); // 0: 当执行fn[0]函数的时候，匿名函数的AO中传入i=0；fn[0]函数的作用域链: [AO, 匿名函数Context.AO, globalContext.VO], 往上找到匿名函数AO中i=0
fn[1](); // 1
fn[2](); // 2



// IIFE例子：
for (var i = 0; i < 5; i++) {
    (function(j) {
        setTimeout(function() {
            console.log(j);
        }, 1000);
    })(i)
}
console.log(i);
// 5 0 1 2 3 4


// iife实现依次输出：0 1 2 3 4 5
async function sleep (time) {
    return return new Promise(resolve => setTimeout(resolve, time))
}
(async function() {
        for(var i = 0; i <= 5; i ++) {
            if (i > 0) await sleep(1000);
            console.log(i);
        }
    }
)()

```


### 什么是闭包陷阱？

如果`过度或不当地使用闭包`，可能会导致一些不易察觉的错误或性能问题，这就是所谓的闭包陷阱。

在React框架中，闭包陷阱可能出现在使用Hooks时。当state更新时，如果闭包引用了旧的state值，而不是最新的state值，就可能导致问题。这是因为闭包会捕获其定义时的变量值，而不是运行时的变量值。

常见的闭包陷阱包括：

1. `内存泄漏`：如果闭包中包含对外部作用域中的大量变量的引用，而且这些变量不再被使用，那么这些变量及其相关的作用域将无法被垃圾回收，从而导致内存泄漏。
2. `变量共享`：由于闭包中的函数共享同一作用域链中的变量，因此闭包中对变量的修改会影响到其他闭包中相同作用域链中的变量，可能导致意外的行为。
3. `循环中的闭包`：在循环中创建闭包时，由于闭包共享了相同的外部作用域，可能会导致意外的结果。比如，在使用 setTimeout 或 setInterval 时，在循环内部创建闭包，会导致闭包中的变量捕获的是循环结束时的值，而不是循环每次迭代的值。
4. `性能问题`：过度使用闭包可能会导致性能问题，因为闭包中的变量在函数执行时需要保持其引用的作用域链，这可能会导致`内存消耗增加`和性能下降。


为了避免闭包陷阱，开发者应该谨慎地使用闭包，并遵循以下原则：
1. `注意内存管理，避免过度依赖闭包引用外部变量`，确保及时释放不再使用的资源。
避免在循环内部创建闭包，以免出现意外的行为。
2. `尽量减少闭包的嵌套和使用范围`，避免性能问题和变量共享带来的意外结果。



### js垃圾回收机制

1. 标记清除
> 当变量进入执行环境是，就标记这个变量为“进入环境”。当变量离开环境时，则将其标记为“离开环境”。

2. 引用计数
> 跟踪记录每个值被引用的次数。当声明了一个变量并将一个引用类型赋值给该变量时，则这个值的引用次数就是1。相反，如果包含对这个值引用的变量又取得了另外一个值，则这个值的引用次数就减1。当这个引用次数变成0时，则说明没有办法再访问这个值了。


常见的内存泄露：`意外的全局变量、没有及时清理的计时器或回调函数、闭包、没有清理的DOM元素引用、Map/Set对象、console`





### js模块化

`全局function模式`: 污染全局命名空间, 容易引起命名冲突或数据不安全，而且模块成员之间看不出直接关系。

`namespace模式`: 减少了全局变量，解决命名冲突; 会暴露所有模块成员，数据不安全

`IIFE模式`: 匿名函数自调用(闭包)，数据是私有的, 外部只能通过暴露的方法操作
> 保证模块的独立性，还使得模块之间的依赖关系变得明显。


`CommonJS`：服务端模块规范，`module.exports、require`

1. 第一次加载某个模块时，Node会缓存该模块。以后再加载该模块，就直接从缓存取出;
2. 输入的是被输出的值的拷贝。也就是说，一旦输出一个值，模块内部的变化就影响不到这个值;
3. 采用同步的方式加载模块: 这并不适合在浏览器环境，同步意味着阻塞加载，浏览器资源是异步加载的；
4. 运行时加载：当使用require命令加载某一个模块时，就会运行整个模块的代码。


`AMD`: （Asynchronous Module Definition，异步模块定义）
> 对于依赖的模块提前执行，依赖前置。

requireJS


`CMD`：（Common Module Definition，通用模块定义）
> CMD 规范专门用于浏览器端，模块的加载是异步的，模块使用时才会加载执行。CMD规范整合了 CommonJS 和 AMD 规范的特点。

SeaJS


AMD vs CMD: 
1. AMD是**依赖关系前置**，在定义模块的时候就要声明其依赖的模块；
2. CMD是**按需加载、依赖就近**，只有在用到某个模块的时候再去require。




`UMD`: 通用模块定义规范（Universal Module Definition）
> 它可以通过运行时或者编译时让同一个代码模块在使用 CommonJs、CMD 甚至是 AMD 的项目中运行, 它没有自己专有的规范，是集结了 CommonJs、CMD、AMD 的规范于一身.



`ES6`: 尽量的静态化，使得编译时就能确定模块的依赖关系

`export, export default, import`

ES6 可以在编译时就完成模块加载，效率要比 CommonJS 模块的加载方式高


es6 vs commonjs:
1. CommonJS 模块输出的是一个值的拷贝，ES6 模块输出的是值的引用；
2. CommonJS 模块是运行时加载，ES6 模块是编译时输出接口；
3. CommonJS 模块的require()是同步加载模块，ES6 模块的import命令是异步加载，有一个独立的模块依赖的解析阶段。


- **箭头函数**

1. 没有自己的this: 指向上一层函数的this;
2. 不能作为构造函数，没有prototype，arguments 属性；
3. 适用于需要匿名函数的地方





### js设计模式

1. 单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点；确保只有一个实例，并提供全局访问。
> 实例如果已经创建，则直接返回；如全局弹窗组件

2. 策略模式: 定义一系列的算法，把它们一个个封装起来，并且使它们可以相互替换; 将算法的使用和算法的实现分离开来; 表单验证

3. **发布订阅模式**：定义了对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都将得到通知。
> 消息的发布者，不会将消息直接发送给特定的订阅者，而是通过消息通道广播出去，然后呢，订阅者通过订阅获取到想要的消息。

4. 装饰者模式：动态地给某个对象添加一些额外的职责，是一种实现继承的替代方案；在不改变原对象的基础上，通过对其进行包装扩展，使原有对象可以满足用户的更复杂需求，而不会影响从这个类中派生的其他对象。



- 观察者模式 vs 发布订阅模式

1. 观察者模式和发布订阅模式最大的区别就是发布订阅模式有个`事件调度中心`。
2. 观察者模式由具体目标调度，每个被订阅的目标里面都需要有对观察者的处理，这种处理方式比较直接粗暴，但是会造成代码的冗余。
3. 而发布订阅模式中统一由`调度中心`进行处理，`订阅者和发布者互不干扰，消除了发布者和订阅者之间的依赖`。这样一方面实现了解耦，还有就是可以实现更细粒度的一些控制。比如发布者发布了很多消息，但是不想所有的订阅者都接收到，就可以在调度中心做一些处理，类似于权限控制之类的。还可以做一些节流操作。




### js跨域方案

1. jsonp: 利用script向服务器端发送请求，仅支持get, 不安全，容易被攻击；
2. CORS: 跨越资源共享, 服务端设置 Access-Control-Allow-Origin 就可以开启 CORS
3. postMessage: 允许来自不同源的脚本采用异步方式进行有限的通信，可以实现跨文本档、多窗口、跨域消息传递。
4. websocket: Websocket是HTML5的一个持久化的协议，它实现了浏览器与服务器的全双工通信，同时也是跨域的一种解决方案
5. node正向代理：前端在webpack中配置`proxy`
6. nginx反向代理：使用nginx反向代理实现跨域，是最简单的跨域方式。只需要修改nginx的配置即可解决跨域问题，支持所有浏览器
> 通过nginx配置一个代理服务器（域名与domain1相同，端口不同）做跳板机，反向代理访问domain2接口~
7. window.name + iframe；window.location.hash + Iframe：监听`onhashchange`事件



### 正向代理和反向代理

- 正向代理：正向代理服务器位于客户端和目标服务器之间，`客户端通过正向代理服务器来访问目标服务器`，所有的请求都需要经过正向代理服务器进行转发。
> 如前端本地开发时，webpack配置的proxy接口代理就是正向代理~

正向代理服务器可以实现访问控制和内容过滤，例如限制访问某些特定的网站或内容，从而提高网络安全性。


- 反向代理：反向代理服务器位于目标服务器和客户端之间，`客户端向反向代理服务器发送请求，然后反向代理服务器将请求转发到目标服务器`，并将目标服务器的响应返回给客户端。
> 如服务端的nginx配置就是反向代理~

反向代理服务器可以实现负载均衡，将请求分发到多个后端服务器上，从而提高服务器的性能和可靠性。




### 如何解决递归容易造成的栈溢出？

尾递归：当一个函数执行时的最后一个步骤是返回另一个函数的调用，这就叫做尾调用。这样就能保证在调用栈中始终只有一个调用记录，避免堆栈溢出。
``` js
// n * n-1 * n-2 * ... * 1
function fn(n, total = 1) {
    if (n===1) return total;
    return fn(n-1, n*total);
}
fn(5) = 120;
```


### 深拷贝问题

**栈溢出**
> 栈溢出的主要原因还是递归；在js中递归非常耗费内存，因为需要同时保存成千上百个调用帧，很容易发生“栈溢出”错误。解决这个问题的方法就是不用递归，改用循环来实现。`while`


**循环引用**
> 循环引用是因为`对象的属性间接或直接的引用了自身`，最终导致死循环；解决循环引用问题，`可以额外开辟一个存储空间，来存储当前对象和拷贝对象的对应关系`，当需要拷贝当前对象时，先去存储空间中找，有没有拷贝过这个对象，如果有的话直接返回，如果没有的话继续拷贝，这样就巧妙化解的循环引用的问题。`Map`


**引用丢失**
> 一个对象a，a下面的两个键值都引用同一个对象b，经过深拷贝后，a的两个键值会丢失引用关系，从而变成两个不同的对象.

> 如果我们发现一个新对象就把这个对象和他的拷贝存下来，每次拷贝对象前，都先看一下这个对象是不是已经拷贝过了，如果拷贝过了，就不需要拷贝了，直接用原来的，这样我们就能够保留引用关系了；解决方法和循环引用的方法差不多。



### 防抖与节流


- 防抖：debounce, 等事件持续触发结束后才去执行一次回调；`resize事件, input搜索事件, keypress事件，按钮点击接口请求`

- 节流：throttle, 在规定的某个时间范围内，该事件最多只执行一次，降低执行频率；`mousemove, srcoll`




### bind 返回的函数，再次 bind 后，上下文是指向哪个？

在 JavaScript 中，bind 方法用于创建一个新的函数，该函数会永久绑定指定的上下文（即函数被调用时的 this 值）。当你再次对已经通过 bind 绑定过上下文的函数使用 bind 方法时，新的 bind 不会影响已经绑定的上下文，而是创建一个新的函数，并保留已绑定的上下文。

``` js
function originalFunction() {
  console.log(this.name);
}

const obj1 = { name: 'Object 1' };
const obj2 = { name: 'Object 2' };

// 第一次绑定上下文
const boundFunction1 = originalFunction.bind(obj1);
boundFunction1(); // 输出: Object 1

// 第二次绑定上下文
const boundFunction2 = boundFunction1.bind(obj2);
boundFunction2(); // 输出: Object 1，因为已经绑定的上下文不受新的 bind 影响
```



### for in 跟 for of 有什么区别，哪个性能更好一些？

1. 迭代对象的方式:
- `for...in`: `用于迭代对象的可枚举属性`，包括对象自身的属性以及继承的属性。在迭代对象时，for...in 循环会遍历对象的键（即`属性名`）。
- `for...of`: `用于迭代可迭代对象`（比如数组、字符串、Set、Map 等），遍历对象的可迭代的属性值。在迭代对象时，for...of 循环会遍历`对象的值`。

2. 迭代效果:
- for...in: 返回的是`键（属性名）`，可以通过键访问到对象的值。
- for...of: 返回的是`值`，可以直接访问到对象的值。

3. 性能:
通常情况下，`for...of 的性能更好`，因为它是`专门用于迭代可迭代对象的语法结构，不会受到原型链的影响`。而 `for...in 则会遍历对象的原型链上的所有可枚举属性，可能会导致性能上的损耗`。不过，在实际开发中，性能差异可能并不明显，而且在迭代对象时，应该根据具体的需求选择合适的迭代方式。



### IntersectionObserver


- IntersectionObserver：可以监听一个元素和可视区域相交部分的比例，然后在可视比例达到某个阈值的时候触发回调。
> 场景：滚动加载更多

- MutationObserver：可以监听对元素的属性的修改、对它的子节点的增删改。
> 场景：监听页面水印是否去掉、监听编辑器变化、画布变化

- ResizeObserver：元素可以用 ResizeObserver 监听大小的改变，当 width、height 被修改时会触发回调。

- PerformanceObserver：用于监听记录 performance 数据的行为，一旦记录了就会触发回调，这样我们就可以在回调里把这些数据上报。
> 浏览器提供了 performance 的 api 用于记录一些时间点、某个时间段、资源加载的耗时等。

- ReportingObserver: 可以监听过时的 api、浏览器干预等报告等的打印，在回调里上报，这些是错误监听无法监听到但对了解网页运行情况很有用的数据。



### requestAnimationFrame比定时器好在哪里？

普通显示器的刷新率约为`60Hz（每秒刷新60次）`, requestAnimationFrame和js中的setTimeout定时器函数基本一致，不过setTimeout可以自由设置间隔时间，而requestAnimationFrame的间隔时间是由浏览器自身决定的，大约是17毫秒（1/60s）左右

定时器的回调函数，会受到js的事件队列宏任务、微任务影响，可能设定的是17毫秒执行一次，但是实际上这次是17毫秒、下次21毫秒、再下次13毫秒执行，所以并不是严格的卡住了这个60HZ的时间，所以有时页面会卡；

requestAnimationFrame能在浏览器下次重绘之前执行指定的回调，能够做到精准严格的卡住显示器刷新的时间，所以不卡





## TS部分

### 泛型

是指在定义函数、接口或类的时候，不预先指定具体的类型，而在使用的时候再指定类型的一种特性。 `<T>`


### type和interface的区别

`type 是 类型别名`，给一些类型的组合起别名，这样能够更方便地在各个地方使用: `type ID = string | number;`

`interface 是 接口`。有点像 type，可以用来代表一种类型组合，但它范围更小一些，只能描述对象结构:

``` ts
interface Position {
    x: number;
    y: string;
}
```

1. type 能表示的任何类型组合。interface 只能表示对象结构的类型。
2. `interface`可以重复声明，`type`不行，继承方式不一样，interface使用extends实现; type 可以通过 `&` 的写法来继承 type 或 interface，得到一个交叉类型：
``` ts
interface Rect extends Shape {
  width: number;
  height: number;
}
type Circle = Shape & { r: number }
```

3. interface 支持声明合并，文件下多个同名的 interface，它们的属性会进行合并, 但同名属性的不能进行类型覆盖修改，否则编译不通过；type 不支持声明合并，一个作用域内不允许有多个同名 type。






## Vue部分


### vue2 vs vue3

1. optionsAPI和compositionAPI
    - optionAPI缺点：
        - 由于所有数据都挂载在 this 之上，因而 Options API 的写法对 TypeScript 的类型推导很不友好，并且这样也不好做 Tree-shaking 清理代码
        - 代码不好复用，Vue 2 的组件很难抽离通用逻辑，只能使用 mixin，还会带来命名冲突的问题。

    - compositionAPI优点：
        - 所有 API 都是 import 引入的。用到的功能都 import 进来，对 Tree-shaking 很友好，没用到功能，打包的时候会被清理掉 ，减小包的大小。
        - 代码方便复用

2. 响应式：Object.defineProperty 和 Proxy
    - defineProperty缺点：不能监听数组的变化、只能劫持对象的属性、必须递归深层遍历
    - proxy优点：针对整个对象、支持数组、api丰富
3. diff算法提升: vue3对于静态的标签和属性会作静态标记
4. 写法改变：
    - setup, createApp, 声明周期，...
    - ref, reactive, toRefs, computed,watch,watchEffect
    - 3支持多个v-model绑定，
    - 3新增Teleport组件：可以将一个组件内部的一部分模板“传送”到该组件的 DOM 结构外层的位置去
5. ts支持：vue2是用flow.js做类型检查，vue3直接用ts写
6. vue3有更好的tree shaking



### React Hooks 与 Vue3 composiiton API 的比较?

> Hook 是 React 16.8 的新增特性。它可以让你在不编写 class 的情况下使用 state 以及其他的 React 特性。

1. `React Hooks 在每次组件渲染时都会调用`，通过隐式地将状态挂载在当前的内部组件节点上，在下一次渲染时根据调用顺序取出；而 `Vue 的 setup() 每个组件实例只会在初始化时调用一次` ，状态通过引用储存在 setup() 的闭包内。


[和 React Hooks 的对比](https://cn.vuejs.org/guide/extras/composition-api-faq.html#comparison-with-react-hooks)



### MVC 和 MVVM

mvc: view => controller => model => view；通信是单向的

> View 传送指令到 Controller；Controller 完成业务逻辑后，要求 Model 改变状态；Model 将新的数据发送到 View，用户得到反馈。


mvvm: view <===> viewmodel <===> model；

>【模型】指的是后端传递的数据。【视图】指的是所看到的页面。【视图模型】mvvm 模式的核心，它是连接 view 和 model 的桥梁。

视图和模型是不能直接通信的。它们通过ViewModel来通信，ViewModel通常要实现一个observer观察者，当数据发生变化，ViewModel能够监听到数据的这种变化；然后通知到对应的视图做自动更新，而当用户操作视图，ViewModel也能监听到视图的变化，然后通知数据做改动，这实际上就实现了数据的`双向绑定`。

1.  MVC模型关注的是Model的不变，所以在MVC模型里，Model不依赖于View，但是 View是依赖于Model的。

2.  MVVM在概念上是真正将页面与数据逻辑分离的模式



### 双向绑定

单向绑定：非常简单，就是把Model绑定到View，当我们用JavaScript代码更新Model时，View就会自动更新

如果用户更新了View，Model的数据也自动被更新了，这种情况就是双向绑定。

实现双向绑定方法：观察者模式（KnockoutJS）、数据模型（Ember）、发布者-订阅者模式（backbone.js）、脏值检查（angular.js）、数据劫持（vue.js）

所谓`数据劫持（也叫数据代理）`，指的是在访问或者修改对象的某个属性时，通过一段代码拦截这个行为，进行额外的操作或者修改返回结果。


基于数据劫持实现双向绑定的实现思路:
1. 利用`Proxy或Object.defineProperty`对对象/对象的属性进行"劫持",在属性发生变化后通知订阅者;
2. 解析器解析模板中的指令，收集指令所依赖的方法和数据, 等待数据变化然后进行渲染;
3. 订阅者接收到数据发生变化,并根据解析器提供的指令进行视图渲染, 使得数据变化促使视图变化。
4. 发布订阅模式：有一个调度中心，用来收集订阅者，对监听器和订阅者进行统一管理



### 虚拟Dom/Diff算法

虚拟DOM，Virtual DOM 就是一个用来描述真实DOM的javaScript对象。虚拟DOM就是`为了解决浏览器性能问题`而被设计出来的

Diff算法是一种对比算法: 对比两者是旧虚拟DOM和新虚拟DOM，对比出是哪个虚拟节点更改了，找出这个虚拟节点，并只更新这个虚拟节点所对应的真实节点，而不用更新其他数据没发生改变的节点，实现精准地更新真实DOM，进而提高效率。



- 虚拟 DOM 的总损耗等于： `虚拟 DOM 增删改 + diff 算法 + 真实 DOM 差异增删改 + 排版与重绘`

- 真实 DOM 的总损耗是: `真实 DOM 完全增删改 + 排版与重绘`


1. 传统的Diff算法通过`循环递归`对节点进行比较，然后判断每个节点的状态以及要做的操作（add，remove，change），最后 根据Virtual DOM进行DOM的渲染; 复杂度为O(n^3)

2. 框架层的diff算法：Web UI 中 DOM 节点跨层级的移动操作特别少，可以忽略不计，所以核心就在于`只对同层节点进行比较，忽略跨层节点的复用`。
> 同层节点的比较也不会两两进行，而是按照一定的顺序比较，或通过 key 属性判断，所以只需要遍历一次新节点，因此算法的复杂度就降低到了O(n)。


React的思路是递增法。通过`从头到尾进行循环遍历`，对比新的列表中的节点，在原本的列表中的位置是否是递增，来判断当前节点是否需要移动。

> 当出现节点跨层级移动时，并不会出现想象中的移动操作，而是把根节点的树被整个重新创建，这是一种影响 React 性能的操作，因此 React 官方建议不要进行 DOM 节点跨层级的操作。

> React 为了突破性能瓶颈，借鉴了`操作系统时间分片`的概念，引入了 `Fiber` 架构。 通俗来说，就是把整个虚拟 DOM 树微观化，变成链表，然后我们利用浏览器的空闲时间计算 Diff。一旦浏览器有需求，我们可以把没计算完的任务放在一旁，把主进程控制权还给浏览器，等待浏览器下次空闲。



Vue2.X Diff `双端比较`：所谓双端比较就是新列表和旧列表两个列表的头与尾互相对比，，在对比的过程中指针会逐渐向内靠拢，直到某一个列表的节点全部遍历过，对比停止。

Vue3 的 Diff 算法与 Vue2 的 Diff 算法一样，也会先进行双端比对，只是双端比对的方式不一样。Vue3 的 `快速Diff算法`借鉴了字符串比对时的双端比对方式，即优先处理可复用的前置元素和后置元素。Vue3 采用了最长递增子序列更进一步地提升了 Diff 算法的性能
> vue3提供了`静态提升方式来优化重复渲染静态节点的问题`，结合静态提升，还对静态节点进行预字符串化，减少了虚拟节点的性能开销，降低了内存占用。




### vue普通插槽的实现原理

Vue模板到真实DOM渲染的过程都会经历：`编译 =》 生成AST => 生成可执行性代码（codegen）` 的过程；

1. 首先父组件在编译过程中，遇到带有slot属性的dom会生成一个特定属性，并给生成的AST元素节点添加该属性；

2. 之后在生成可执行性代码过程中，会给当前父组件 data 添加一个 slot 属性，指向该带有slot属性的dom；

3. 之后子组件在编译时如果遇到`<slot>`模块，则给对应的 AST 元素节点添加 `slotName` 属性；

4. 接着子组件在生成可执行性代码过程中，会通过这个`slotName`生成需要渲染的slot内容; 又因为子组件在渲染初始化时其实父组件已经编译完成，那么，子组件在渲染初始化的时候，可以拿到父组件中已经生成的所有 children；

5. 通过循环遍历这些 children 就可以拿到父组件里面嵌套的 vnodes; 这样子组件在渲染时，就可以通过 slotName 来获取需要渲染的内容了，从而实现子组件渲染时把`<slot></slot>`里面的内容渲染为在外层父组件中传入的 dom。


### v-model实现原理

v-model是`value属性+$emit('input')事件`的语法糖。

1. 首先在编译阶段，v-model 被当做普通的指令解析到 el.directives 中；在编译的时候会传入vue内置的指令：`v-model, v-text, v-html...`；
2. 接着在 `生成可执行性代码` 阶段，会遍历 el.directives，然后获取`v-model`指令对应的方法；
3. 其实就是动态绑定了 input 的 value 指向了 msg 变量，并且在触发 input 事件的时候去动态把 msg 设置为目标值，这样实际上就完成了数据双向绑定了，所以说 v-model 实际上就是语法糖。



### vue中keep-alive的实现原理

keep-alive 组件是一个抽象组件，它的实现通过自定义 render 函数并且利用了插槽，会 缓存 vnode。

1. 在组件首次渲染的时候，它的父组件`<keep-alive>` 的 `render` 函数会先执行，keep-alive会将该组件实例缓存起来；
2. 当再次渲染该组件时，在它的父组件`keep-alive`做 `diff` 数据更新的逻辑中，需要对自己的 `children`，也就是这些 `slots` 做重新解析, 并触发 `<keep-alive`> 组件实例 `$forceUpdate` 逻辑，也就是重新执行 `<keep-alive>` 的 render 方法；
3. 这时组件如果命中keep-alive的缓存，那就直接返回缓存的组件实例；
4. 之后组件就不会走跟首次渲染一样创建组件实例的逻辑，也不会执行组件的 `created、mounted` 等钩子函数了，而是直接将缓存的 DOM 对象直接插入到目标元素中；
5. 在渲染的最后一步，会有一个处理：如果是被 `<keep-alive>` 包裹的组件已经渲染完毕, 则给所有组件加上`activated`的生命周期；同时在`destroy`钩子函数中加上`deactivated`生命周期。


keep-alive 的中还运用了 `LRU(最近最少使用) 算法`，选择最近最久未使用的组件予以淘汰
> LRU 的核心思想是如果数据最近被访问过，那么将来被访问的几率也更高，所以我们将命中缓存的组件 key 重新插入到 `缓存队列` 的尾部，这样一来，缓存组件队列 中越往头部的数据即将来被访问几率越低，所以当缓存数量达到最大值时，我们就删除将来被访问几率最低的数据，即 缓存队列 中第一个缓存的组件。





### vue生命周期

加载渲染：父 beforeCreate -> 父 created -> 父 beforeMount -> 子 beforeCreate -> 子 created -> 子 beforeMount -> 子 mounted -> 父 mounted


子组件更新：父 beforeUpdate -> 子 beforeUpdate -> 子 updated -> 父 updated

销毁过程：父 beforeDestroy -> 子 beforeDestroy -> 子 destroyed -> 父 destroyed

可以在钩子函数 created、beforeMount、mounted 中进行异步请求



优先级：组件 > mixin > extend



### 组件data为什么是一个函数？

为了确保每个实例可以维护一个独立的、互不干扰的数据副本； 隔离作用域。


当 Vue 实例化一个组件时，它会调用 data 函数来初始化该实例的数据对象。如果 data 是一个对象，那么所有的实例将会共享同一个数据对象，这意味着对任何一个实例的数据修改都会影响到其他所有实例。

当 data 被定义为一个函数时，每次创建组件的新实例时，Vue 都会调用这个函数来初始化数据。由于`函数调用会创建一个新的执行上下文，并返回一个新的对象，因此每个实例都会得到一个独立的数据副本`。这样，修改一个实例的数据就不会影响到其他实例。



### vm.$set 的实现原理

1. 如果目标是数组，直接使用数组的 splice 方法触发响应式；
2. 如果目标是对象，会先判读属性是否存在、对象是否是响应式，最终如果要对属性进行响应式处理，则是通过调用 `defineReactive` 方法进行响应式处理
> defineReactive 方法就是  Vue 在初始化对象时，给对象属性采用 Object.defineProperty 动态添加 getter 和 setter 的功能所调用的方法


### vue mixins有什么缺点?

1. 命名冲突：如果不小心，混入的属性或方法可能会`与组件本身的属性或方法产生命名冲突`，导致意外行为或错误。

2. 隐式依赖：使用混入时，组件的行为可能依赖于未在组件定义中明确列出的混入。这`使得组件的行为更难以理解和跟踪`。

3. 多重继承：如果`多个混入对象具有相同名称的属性或方法`，Vue将无法正确确定哪个混入对象应该拥有优先级。

4. `耦合度增加`：混入增加了组件与混入对象之间的耦合度，导致代码更难以维护和理解。

5. `不利于代码追踪和调试`：当组件使用了多个混入时，如果出现了问题，追踪和调试起来可能会变得更加困难，因为组件的行为分散在多个混入对象中。



### new Vue()执行了哪些流程?

1. `初始化Vue实例`： 创建一个新的 Vue 实例对象，并执行 Vue 构造函数。

2. `合并配置`： 将用户传入的配置选项与默认配置选项进行合并，生成最终的配置对象。通常配置选项包括 data、methods、computed、watch、props、components、created、mounted 等。

3. `初始化生命周期钩子`： 在合并配置完成后，Vue 将初始化实例的生命周期钩子，如 beforeCreate、created、beforeMount、mounted 等。

4. `初始化事件系统`： Vue 实例化过程会初始化事件系统，即为实例绑定事件监听器，以便在实例的生命周期中触发对应的事件。

5. `初始化数据响应式`： Vue 会对配置中的 data 属性进行响应式处理，`通过 Object.defineProperty 或 Proxy 等机制实现对数据的监听`，并为数据添加 getter 和 setter。

6. `初始化依赖注入`： Vue 实例化过程会初始化依赖注入系统，以便在组件中进行依赖注入。

7. `初始化组件`： 如果配置选项中包含 components，Vue 将初始化组件，即注册组件，使其在模板中可以使用。

8. `编译模板`： 如果配置选项中包含 template，Vue 将对模板进行编译，生成渲染函数。

9. `挂载实例`： 将实例挂载到 DOM 上，即执行 vm.$mount() 方法，将 Vue 实例与页面中的 DOM 元素进行关联。

10. `触发生命周期钩子`： 在实例挂载完成后，Vue 将依次触发 beforeMount 和 mounted 生命周期钩子。

11. `完成实例化`： 当上述步骤全部完成后，Vue 实例化过程就完成了，此时可以通过实例对象访问数据、方法、计算属性等，并可以响应用户的操作和事件。





### vue组件中style标签设置scoped的作用是什么，原理是什么

在Vue组件中，当你使用 scoped 属性添加到 `<style>` 标签时，它的作用是限制该样式仅在当前组件内生效，而不会影响到其他组件或全局样式。这种方式被称为 "Scoped CSS"。


原理是通过 Vue 编译器`在编译过程中`，将 scoped 属性添加到样式标签后，`会自动为该组件的每个样式规则（包括选择器）生成一个唯一的属性`，用于标识当前组件内的元素; 然后将该属性添加到相应的 HTML 元素上。这样一来，该样式规则就只会应用于带有相应唯一属性的元素，从而实现了`样式的局部作用域`。





## Webpack部分


### webpack devServer 热更新（HMR）原理？

动态模块热加载, Hot Module Replacement，简称HMR，无需完全刷新整个页面的同时，更新模块。


1. 启动一个本地http服务，让浏览器可以请求本地静态资源；再去启动 websocket 服务，通过 websocket，可以建立本地服务和浏览器的双向通信。这样就可以实现当本地文件发生变化，立马告知浏览器可以热更新代码。

2. 之后每次修改代码，就会触发编译；这是通过 webpack-dev-middleware 实现的：编译结束后，开启对本地文件的监听，当文件发生变化，重新编译，编译完成之后继续监听。
> 监听本地文件的变化主要是通过文件的生成时间是否有变化, 从而实现代码的改动保存会自动编译，重新打包。

3. 每次编译都会生成`hash值、已改动模块的json文件、已改动模块代码的js文件`, 编译完成后通过socket向客户端推送`当前编译的hash戳`；
> 将编译后的文件打包到内存：开发的过程中，你会发现dist目录没有打包后的代码，因为都在内存中。原因就在于访问内存中的代码比访问文件系统中的文件更快，而且也减少了代码写入文件的开销。

4. 客户端的websocket监听到有文件改动推送过来的hash戳，会和上一次对比：一致则走缓存，不一致则通过向服务端获取最新资源；使用内存文件系统去替换有修改的内容实现局部刷新.





### postcss-loader 与 less/scss的区别？

postcss 一种对css编译的工具，类似babel对js的处理。常见功能有：`自动补全浏览器前缀、使用下一代css语法`等等

less sass 是预处理器，用来支持扩充css语法；

postcss 既不是 预处理器也不是 后处理器, 它鼓励开发者使用规范的CSS原生语法编写源代码，支持未来的css语法，就像babel支持ES6。

postcss功能：把 CSS 解析成 JavaScript AST；然后调用插件来处理 AST 并得到结果，如`autoprefixer`自动补齐css3前缀~

> autoprefixer是css的后置处理器(打包之后进行处理)，sass、less是css的预处理器(在打包之前进行处理)。


### module、chunk、bundle

module：对于一份同逻辑的代码，当我们手写下一个一个的文件，它们无论是 ESM 还是 commonJS 或是 AMD，他们都是 module ；

chunk：当我们写的 module 源文件传到 webpack 进行打包时，webpack 会根据文件引用关系生成 chunk 文件，webpack 会对这个 chunk 文件进行一些操作；表示的是`文件依赖关系`

bundle：webpack 处理好 chunk 文件后，最后会输出 bundle 文件，这个 bundle 文件包含了经过加载和编译的最终源文件，所以它可以直接在浏览器中运行。

> 我们直接写出来的是 module，webpack 处理时是 chunk，最后生成浏览器可以直接运行的 bundle。


### hash、chunkhash、contenthash

hash：hash 是跟整个 webpack 构建项目相关的，每次项目构建 hash 对应的值都是不同的，即使项目文件没有做“任何修改”；

chunkhash：跟 webpack 打包的 chunk 相关，具体来说webpack是根据入口 entry 配置文件来分析其依赖项并由此来构建该 entry 的 chunk，并生成对应的 hash 值；不同的 chunk 会有不同的 hash 值。

contenthash：表示由文件内容产生的hash值，内容不同产生的contenthash值也不一样。在项目中，通常做法是把项目中css都抽离出对应的css文件来加以引用。所以css文件最好使用contenthash。


### treeing shaking(摇树优化)

1个模块可能有多个方法，只要其中的某个方法使用到了，则整个文件都会被打到bundle里面去，tree shaking就是只把用到的方法打到bundle，没用到的方法会在uglify阶段被擦除掉。



`必须是es6的语法`; 通过静态分析，将没用的代码注释标记，在编译阶段删除无用代码
> esm 要求所有的导入导出语句只能出现在模块顶层，且导入导出的模块名必须为字符串常量; 所以，ESM 下模块之间的依赖关系是高度确定的，与运行状态无关，编译工具只需要对 ESM 模块做`静态分析`，就可以从代码字面量中推断出哪些模块值未曾被其它模块使用，这是实现 Tree Shaking 技术的必要条件。


DCE(dead code elimination)死码消除: 编译过程中，移除对程序运行结果没有任何影响的代码。

1. 收集模块导出变量；模块导出信息收集完毕后，Webpack 需要标记出各个模块的导出列表中哪些导出值有被其它模块用到，哪些没有;
2. 经过前面的收集与标记步骤后，Webpack 已经记录了每个模块都导出了哪些值，每个导出值又没被哪些模块所使用；
3. 最终模块导出列表中未被使用的值都不会定义在webpack的导出对象中，形成一段不可能被执行的 `Dead Code`；
4. 在此之后，将由 `Terser、UglifyJS` 等 DCE 工具“摇”掉这部分无效代码，构成完整的 Tree Shaking 操作。
> 标记功能只会影响到模块的导出语句，真正执行“Shaking”操作的是 Terser 插件。



- Scope Hoisting: 通过scope hoisting可以减少函数声明代码和内存开销。
> 分析出模块之间的依赖关系，尽可能的把打散的模块合并到一个函数中去，但前提是不能造成代码冗余。



### webpack5 vs webpack4

1. Webpack5 提供了内置的静态资源构建能力，我们不需要安装额外的 loader（url-loader，file-loader，raw-loader）
2. webpack5 中内置了 Cache 来实现启动缓存，实现了二次构建的提速, v4 需要引入插件hard-source-webpack-plugin
3. js压缩：webpack v5 开箱即带有最新版本的 terser-webpack-plugin。如果希望自定义配置，那么仍需要安装 terser-webpack-plugin。v4 则必须安装 terser-webpack-plugin v4 的版本
4. 启动服务差别：v4 通过 webpack-dev-server 启动服务，v5 内置使用 webpack serve 启动
5. tree-shaking的优化：v5 能够处理对嵌套模块的 tree shaking，也能处理对 Commonjs 的 tree shaking




### eslint, prettier, stylelint

ESLint 是JavaScript 的代码检验工具, 用于查找并修复 JS 代码中的问题，并且支持部分问题自动修复。其核心是通过对代码解析得到的 AST 进行模式匹配，来分析代码达到检查代码质量和风格问题的能力。

Prettier 代码格式化工具，聚焦于代码的格式化，通过语法分析，重新整理代码的格式，让所有人的代码都保持同样的风格; 能对 html, css, js 文件进行格式化
> 原理是将代码生成AST语法树，之后是处理AST，最后生成代码。

StyleLint 是『一个强大的、现代化的 CSS 检测工具』, 与 ESLint 类似, 是通过定义一系列的编码风格规则帮助我们避免在样式表中出现错误。



### webpack vs vite

1. webpack 的本质就是`先打包，再加载`；Vite 在开发环境下，`模块以原生 esm 的形式被浏览器加载, 生产环境下，模块被 Rollup 以传统方式打包`。
2. Webpack 会先打包，然后启动开发服务器，请求服务器时直接给予打包结果；而 Vite 是直接启动开发服务器，`请求哪个模块再对该模块进行实时编译`; vite在启动时不需要分析模块的依赖、不需要编译, 因此启动速度非常快.
3. webpack 因为只针对打包不预设场景，所以设计得极其灵活，不局限于针对 web 打包，几乎所有可配置的环节都做成了可配置的, 缺点就是配置项极度复杂; Vite 的选择是`缩窄预设场景来降低复杂度`。如果预设了 web 的场景，那么大部分常见的 web 构建需求都可以直接做成默认内置
4. Vite 支持开箱即用的引入 .ts 文件，.jsx 与 .tsx 也是开箱即用，也为 Vue 提供第一优先级的支持; 而webpack则需要引入各种loader将文件编译为.js文件。
4. 从打包成品来看：webpack是包了一大堆iife闭包， Vite用 Rollup 打包，rollup则简洁得多


### vite快的原因?

1. 减少了开发服务器启动时间：
    - webpack 需要对所有运行资源进行`提前编译处理，对依赖模块进行了语法分析转义`，最终将模块被打包到内存中；
    - Vite 在第一次加载的时候会使用 esbuild 预构建依赖, 预构建可以提高页面加载速度：`通过依赖预构建，Vite 将有许多内部模块的 ESM 依赖关系转换为单个模块，以提高后续页面加载性能。` 
    - Vite 以原生 ESM 方式提供源码，在浏览器请求对应URL时，再提供文件，实施了真正的路由懒加载，这个比起Webpack就要节省了不少时间。
2. Vite减少了热更新时间:
    - webpack虽然支持动态模块热重载（HMR），即允许一个模块 “热替换” 它自己，而不会影响页面其余部分，但实践证明，其`热更新速度也会随着应用规模的增长而显著下降`。
    - 在 Vite 中，HMR 是在原生 ESM 上执行的。当`改动了一个模块后，仅需让浏览器重新请求该模块即可，不像webpack那样需要把该模块的相关依赖模块全部编译一次，效率更高`。
3. Vite 同时利用 HTTP 头来加速整个页面的重新加载：源码模块的请求会根据 304 进行协商缓存，而依赖模块请求则会进行强缓存，因此一旦被缓存它们将不需要再次请求。 




### webpack原理？

1. 初始化：读取传入的脚本命令参数；传入配置参数，通过调用webpack提供的编译方法，创建编译对象；开始注册传入的webpack插件, 之后开始进行打包；

Webpack 中的插件机制就是基于 `Tapable` 实现与打包流程解耦，插件的所有形式都是基于 `Tapable` 实现。

tapable提供了各种各样的hook来帮我们管理事件是如何执行; 比如我注册了三个事件，我可以希望他们是并发的，或者是同步依次执行，又或者其中一个出错后，后面的事件就不执行了，这些功能都可以通过 tapable 的 hook 实现。

整个过程中webpack会通过发布订阅模式，向外抛出一些hooks，而webpack的插件即可通过监听这些关键的事件节点，执行插件任务进而达到干预输出结果的目的。


2. 模板编译阶段：从入口文件（entry）开始解析，并且找到其导入的依赖模块，递归遍历分析，形成依赖关系树；

对不同文件类型的依赖模块文件使用对应的Loader进行编译，最终转为Javascript文件；

每个模块间的依赖关系，依赖于AST语法树。每个模块文件在通过Loader解析完成之后，会通过acorn库生成模块代码的AST语法树，通过语法树就可以分析这个模块是否还有依赖的模块，进而继续循环执行下一个模块的编译解析。


3. 输出文件阶段: 整理模块依赖关系，同时将处理后的文件输出到ouput的目录中; 最终Webpack打包出来的bundle文件是一个IIFE的执行函数。



::: tip **具体来说，Webpack 会做以下几件事情：**
1. `解析模块`：Webpack 会解析项目的所有模块，包括 JavaScript 文件、CSS 文件、图片等，将它们转换为模块。
2. `构建依赖图`：Webpack 会根据模块的导入和导出关系，构建一个依赖图，确保所有依赖关系都被正确解析。
3. `转换和优化`：根据配置，Webpack 会对模块进行各种转换和优化操作，如 Babel 转译、压缩、代码分割等。
4. `打包输出`：最后，Webpack 会将处理后的模块打包成一个或多个 bundle，输出到指定的目录。
:::



### webpack Loader

Webpack中的Loader本质上就是一个函数，这个函数会在我们在我们加载一些文件时执行, 比如常见的file-loader、vue-loader、babel-loader等，专门用于打包时解析各种类型的文件。

实现箭头函数转普通函数：
1. 分析AST结构: 变成普通函数之后就不叫箭头函数ArrowFunctionExpression，而是函数表达式FunctionExpression
2. 修改AST结构，生成新的语法树；（@babel/types 集成了一些快速生成、修改、删除 AST Node的方法）
3. 跟其他loader一样在配置中引入，运行，bundle.js中就会看到箭头函数转成普通函数了


### webpack plugins

plugin通常是在webpack在打包的某个时间节点做一些操作，我们使用plugin的时候，一般都是new Plugin()这种形式使用，所以，首先应该明确的是，plugin应该是一个类。


plugin的核心在于，可以操作webpack本次打包的各个时间节点（hooks，也就是生命周期勾子），在不同的时间节点做一些操作。





### AST原理

`抽象语法树（Abstract Syntax Tree，AST）`，或简称语法树（Syntax tree），是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构，树上的每个节点都表示源代码中的一种结构。webpack、eslint 等很多工具库的核心都是通过抽象语法书这个概念来实现对代码的检查、分析等操作。

1. 词法分析：读取我们的代码，然后把它们按照预定的规则合并成一个个的标记（tokens），整个代码将被分割进一个tokens列表；（类似英语中将句子拆成单词）

2. 语法分析：它会将词法分析出来的列表转化成树形的表达形式。同时，验证语法，语法如果有错的话，抛出语法错误；即生成AST语法树；

3. 代码生成：将 AST 转换成一系列可执行的机器指令代码：遍历初始的 AST，对其结构进行改造，再将改造后的结构生成对应的代码字符串。


AST使用场景：
1. 语法检查、代码风格检查、格式化代码、语法高亮、错误提示、自动补全：ESlint、Prettier、Vetur等; 
2. 代码混淆压缩：uglifyJS等。
3. 代码转译：webpack、babel、TypeScript等。



### babel原理

1. 解析 (Parsing)：这个过程由编译器实现，会经过词法分析过程和语法分析过程，从而生成 AST。
2. 读取/遍历 (Traverse)：深度优先遍历 AST ，访问树上各个节点的信息（Node）。
3. 修改/转换 (Transform)：在遍历的过程中可对节点信息进行修改，生成新的 AST。
4. 输出 (Printing)：对初始 AST 进行转换后，根据不同的场景，既可以直接输出新的 AST，也可以转译成新的代码块。



### SouceMap

sourceMap是一项将编译、打包、压缩后的代码映射回源代码的技术，里面`储存着源码的位置信息`。

映射文件以`.map`结尾，这个文件里保存的是转换后代码的位置，和对应的转换前的位置。

devtool:
1. source-map // 单独生成.map文件 可定位到源代码
2. eval-source-map：内联。每一个文件都生成对应的 Source Map，都在 eval 中，可以查看错误代码准确信息 和 源代码的错误位置。
3. cheap-source-map // 只能定义行的信息，定位不到列的信息




### package.json vs package.lock.json

package.json 用来描述项目及项目所依赖的模块信息。

package-lock.json： 锁定node包版本号，对整个依赖树进行版本固定的；为了解决这个不同人电脑安装的所有依赖版本都是一致的，确保项目代码在安装所执行的运行结果都一样



版本号由三部分组成：`major.minor.patch，主版本号.次版本号.修补版本号（补丁）`。
1. `补丁`中的更改表示不会破坏任何内容的错误修复。
2. `次要版本`的更改表示不会破坏任何内容的新功能。
3. `主要版本`的更改代表了一个破坏兼容性的大变化。 如果用户不适应主要版本更改，则内容将无法正常工作。


`~` 锁定次要版本：会匹配最近的小版本依赖包，比如 ~1.2.3 会匹配所有 1.2.x 版本，但是不包括 1.3.0

`^` 只是锁定主要版本：会匹配最新的大版本依赖包，比如 ^1.2.3 会匹配所有 1.x.x 的包，包括 1.3.0，但是不包括 2.0.0

`*` 安装最新版本的依赖包，比如 *1.2.3 会匹配 x.x.x，



## 前端监控


`数据监控`：pv, uv, 用户在每一个页面的停留时间, 用户通过什么入口来访问该网页, 用户在相应的页面中触发的行为,...

pv: page view, 页面浏览量或点击量

uv: user view, 访问某个站点或点击某条新闻的不同 IP 地址的人数

`性能监控`：首屏加载时间，白屏时间，http请求响应时间，静态资源下载时间，页面渲染时间，页面交互动画完成时间 。。。


`异常错误监控`：javascript 的异常监控，样式丢失的异常监控，静态资源加载异常，Promise异常，接口异常，跨域异常 。。。


`前端监控的搭建流程`分以下几个阶段：
1. 采集阶段：数据的采集, 开发者可以通过 window.performance 属性获取。
    - 页面性能情况：
        - FP（白屏）First-Paint 首次渲染：表示浏览器从开始请求网站到屏幕渲染第一个像素点的时间。
        - FCP（灰屏） First-Contentful-Paint 首次内容渲染：表示浏览器渲染出第一个内容的时间，这个内容可以是文本、图片或SVG元素等等，不包括iframe和白色背景的canvas元素。
        - LCP Largest Contentful Paint,最大内容绘制：LCP 是页面内首次开始加载的时间点，到 可视区域内最大的图像或者文本块完成渲染 的 相对时间
        - `首次输入延迟（FID）`: FID 是`从用户第一次与页面交互直到浏览器对交互作出响应`，并实际能够开始处理事件处理程序所经过的时间。一般 <= 100ms 最佳
    - 异常数据收集：`try/catch, window.onerror, window.addEventListener('error'), unhandledrejection`
        - 前端异常：js报错、promise异常、静态资源加载异常...
        - 接口异常：未响应/响应超时，4xx请求异常, 5xx服务器异常
    - 环境信息：业务信息，设备信息，网络信息，SDK信息。
    - 行为数据：用户行为（pv,uv,点击事件,埋点...）、浏览器行为、控制台打印行为。

2. 数据上报：搭建 API 应用，接收采集到的数据: `sourcemap，第三方sdk, 1*1gif`
    - `1*1gif优点`：可以进行跨域，不会携带cookie；只需要发送数据；不会阻塞页面加载；只需 new Image 对象，相比于 png/bmp 体积最小，可以节约网络资源

3. 数据存储：API 应用对接数据库，将采集到的数据存起来: `MongoDB`
    - 数据清洗：削峰处理，预处理，分类，聚合

4. 查询统计：对采集到的数据进行查询，统计，分析：
5. 可视化：前端通过 API 查询统计数据，做可视化展示
6. 报警：API 对接报警通知服务，如钉钉
7. 部署：应用整体部署上线


- **前端容灾**

前端容灾指的因为各种原因后端接口挂了(比如服务器断电断网等等)，前端依然能保证页面信息能完整展示。比如 banner 或者列表之类的等等数据是从接口获取的，要是接口获取不到了，怎么办呢？

1. LocalStorage：在接口正常返回的时候把数据都存到 LocalStorage
2. CDN：每次更新都要备份一份静态数据放到CDN；在接口请求失败的时候，并且 LocalStorage 也没有数据的情况下，就去 CDN 摘取备份的静态数据。
3. Service Worker：假如不只是接口数据，整个 html 都想存起来，就可以使用 Service Worker 做离线存储；利用 Service Worker 的请求拦截，不管是存接口数据，还是存页面静态资源文件都可以。


### 前端埋点

1. `代码埋点（也称为手动埋点或侵入式埋点）`：这是由开发人员手动在代码内植入预埋点的方式。开发人员需要确定埋点的位置、时间和触发机制。代码埋点有两种常见类型：命令式和声明式。命令式埋点通常在一些事件操作的回调函数中进行，如点击事件的回调函数、页面的生命周期、ajax回调等。而声明式埋点则是将埋点信息封装在自定义属性中，通过SDK识别自定义属性然后获取埋点数据。

2. `可视化埋点`：这种埋点方式`以业务代码为输入，通过可视化系统配置埋点，最后以耦合的形式输出业务代码和埋点代码`。这种方式可以简化埋点过程，提高开发效率。

3. `无痕埋点（也称为无差别埋点或全埋点）`：这种埋点方式无差别地对全局所有事件和页面加载生命周期等进行拦截全埋点。无痕埋点可以收集到更全面的用户行为数据，但可能会收集到一些不必要的信息, 需要后端进行数据清洗


## CI/CD


**CI（continuous integration）** 的意思是 `持续构建` ,也被称为持续集成：在源代码变更后`自动检测、拉取、构建`的过程。

**CD**，持续部署（Continuous Deployment） 和 持续交付（Continuous Delivery）。持续交付的概念是：`将制品库的制品拿出后，部署在测试环境 / 交付给客户提前测试`。持续部署则是`将制品部署在生产环境`。


写一个自己的网站放到服务器上：`编写代码 -> （单元测试/集成测试） -> 上传至代码仓库 -> 打包构建 -> 上传至服务器 -> 配置 Nginx/Apache 将 80 端口映射至网站文件夹`
> 有了 `CI/CD` 的系统之后，我们就只需要编写代码，剩下的步骤都交给 CI/CD 系统来处理，这极大地解放了我们的双手，提升了开发效率。



### Docker

是一个开源的应用容器引擎。`开发者可以将自己的应用打包在自己的镜像里面`，然后迁移到其他平台的 Docker 中。镜像中可以存放你自己自定义的运行环境，文件，代码，设置等等内容，再也不用担心环境造成的运行问题。镜像共享运行机器的系统内核。

Docker 的优势在于 快速，轻量，灵活。开发者可以制作一个自己自定义的镜像，也可以使用官方或者其他开发者的镜像来启动一个服务。通过将镜像创建为容器，容器之间相互隔离资源和进程不冲突，但硬件资源又是共享的。

`镜像`是一个可执行包，其包含运行应用程序所需的代码、运行时、库、环境变量和配置文件，`容器`是镜像的运行时实例。镜像是一个静态的概念，不包含任何动态数据，其内容在构建之后也不会被改变。

我们可以使用 Docker 将应用打包成一个镜像，交给 Kubernetes 去部署在目标服务集群。并且可以将镜像上传到自己的镜像仓库，做好版本分类处理。


**Dockerfile** 文件是一个文本文件，用来配置 image; 使用 `Dockerfile` 文件可以让构建镜像更具备可重复性，同时保证启动脚本和运行程序的标准化。

**docker-compose** 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 `YML` 文件来配置应用程序需要的所有服务。



### Jenkins

是一个持续构建工具平台，主要`用于持续、自动的构建/测试你的软件和项目`。它可以执行你预先设定好的设置和构建脚本，也可以和 Git 代码库做集成，实现`自动触发和定时触发构建`。



### Docker vs Jenkins

1. Jenkins 时刻替我们监控 git 仓库，当我们提交了新代码，需要让新代码发生作用，我们只需要在 Jenkins 上点击构建，它就会主动去 git 仓库拉取对应分支最新的代码，然后进行build打包，把打包好的文件放置到 nginx 的指定目录去，这样我们就能在浏览器看到最新的效果；

2. docker 可以为每个服务提供一个容器(container)，容器包含服务所需的所有条件，服务运行其中，不同容器之间互不干扰。另外，docker 是根据镜像来创建容器的。

它们二者可以分开使用，也可以合作起到更好的效果。jenkins 是构建服务并将服务推送到指定位置去的，这个服务本身也可以是个 docker 镜像。
> 可以在 Dock Hub 中搜索jenkins镜像，服务器上安装jenkins服务也可以通过docker镜像安装。



### Kubernetes

看作是用来是一个部署镜像的平台。可以用来操作多台机器调度部署镜像，大大地降低了运维成本。
> 如果你将 docker 看作是飞机，那么 kubernetes 就是飞机场。在飞机场的加持下，飞机可以根据机场调度选择在合适的时间降落或起飞。


**灰度发布**是一种发布方式，也叫 `金丝雀发布`：会在现存旧应用的基础上，启动一个新版应用。但是新版应用并不会直接让用户访问。而是先让测试同学去进行测试。如果没有问题，则可以将真正的用户流量慢慢导入到新版上。在这中间，持续对新版本运行状态做观察，直到慢慢切换过去，这就是所谓的`A/B测试`。 当然，你也可以招募一些 `灰度用户`， 给他们设置独有的灰度标示（Cookie，Header），来让他们可以访问到新版应用。



### GitHub Actions

是一种持续集成和持续交付 (CI/CD) 平台，可用于自动执行生成、测试和部署管道。 您可以创建工作流程来构建和测试存储库的每个拉取请求，或将合并的拉取请求部署到生产环境。

正常需求的开发流程为：`需求 => 开发 => 构建 => 测试 => 预发 => 部署`

Github Actions 是GitHub的持续集成服务。持续集成由很多操作组成，比如登录远程服务器，发布内容到第三方服务等等，这些相同的操作完全可以提取出来制作成脚本供所有人使用。



## Serverless

又叫无服务器，是一种计算模型，这种模型使开发人员能够构建和运行应用程序而无需管理底层的服务器基础设施。 

在传统的服务器模型中，开发人员需要自行购买、配置和管理服务器来运行应用程序。 而在 Serverless 模型中，开发人员只需关注应用程序的代码逻辑，而不需要担心服务器的管理。



## 微前端

微前端是一种设计架构，并不是技术。是借鉴于微服务思想的设计架构，是一种为了解决庞大且难以维护的项目的方案。

微前端解决了什么问题: `大型应用程序的维护困难, 大型应用程序的可扩展性问题, 多团队协同开发问题`

微前端具备的核心价值: `技术栈无关, 独立开发、独立部署, 增量升级（渐进式重构）, 独立运行时`

微前端架构方案：
1. `基座模式`：将多个子应用程序作为模块加载到一个主应用程序中。这些模块是独立的小型应用程序。每个子应用程序都可以独立开发、测试、部署，而主应用程序主要就是将子应用进行集成和协调，子应用程序发生变化，主应用程序也会自动的完成更新。

`Single-SPA`：一个支持多框架、多技术栈的JavaScript微前端框架，用于构建大型单页应用程序。

`qiankun`：一个基于Single-SPA封装的微前端框架，支持React、Vue、Angular等技术栈。



**Q: why not iframe ?**

iframe 最大的特性就是提供了浏览器原生的硬隔离方案，不论是样式隔离、js 隔离这类问题统统都能被完美解决。但他的最大问题也在于他的隔离性无法被突破，导致`应用间上下文无法被共享，随之带来的开发体验、产品体验的问题`：`UI 不同步，DOM 结构不共享, 全局上下文完全隔离，内存变量不共享, 加载慢...`


`微前端解决的是隔离和通信，monorepo解决的是组件共享`




## Monorepo

`单仓库，多项目`。就是指在一个大的项目仓库中，管理多个模块/包（package），这种类型的项目大都在项目根目录下有一个packages文件夹，分多个项目管理。


包关联配置: `pnpm-workspace.yaml`， 在 pnpm 中使用 `workspace: 协议定义某个依赖包版本号`时，pnpm 将只解析存在工作空间内的依赖包，不会去下载解析 npm 上的依赖包。


### 组件库

**Q: 怎么展示我们的 demo 组件，以及怎么展示 demo 源码呢？**

> 组件直接渲染即可，难的是展示源码；可以约定一个语法规则，在模块加载的时候通过正则匹配拿到demo组件的路径和名称，同时也可以拿到demo源码；之后就可以通过改写模块属性，把源码内容转成字符串添加到模块中；之后在预览组件中拿到源码字符串sourceCode，就可以进行展示了~

这里我约定的语法规则是`source-code="ui:::xxx"`, 写一个简单的vite插件，用于将所有md模块中的`source-code="ui:::xxx"`提取出来，并通过路径获取源码信息


- 样式隔离：iframe

- 组件库打包：vite进行打包, 它提供了一个库模式 (opens new window)专门用于打包库组件~


### 代码规范

1. 通过 eslint 完成对规则的限制
2. 通过 prettier 完成对格式化定义，以及使用 eslint-config-prettier 抹平与 eslint 自带格式化的冲突问题
3. 通过 stylelint 完成对 css 的检查和格式化
4. 通过 husky 添加 pre-commit 钩子，在代码提交之前进行校验
5. 通过 commitLint规范代码提交格式
6. 通过 lint-staged 完成只对暂存区代码的校验和格式化工作



### 封装组件的原则

1. 单一原则：负责单一的页面渲染
2. 多重职责：负责多重职责，获取数据，复用逻辑，页面渲染等
3. 明确接受参数：必选，非必选，参数尽量设置以_开头，避免变量重复
4. 可扩展：需求变动能够及时调整，不影响之前代码
5. 代码逻辑清晰
6. 封装的组件必须具有高性能，低耦合的特性
7. 组件具有单一职责：封装业务组件或者基础组件，如果不能给这个组件起一个有意义的名字，证明这个组件承担的职责可能不够单一，需要继续抽组件，直到它可以是一个独立的组件即可



## 低代码


页面核心构成：
1. 组件区：提供可以被反复拖拽的组件
2. 设计区：可以将组件拖拽到设计区，并移动位置
3. 属性区：可以定制化的配置每一个拖到设计区的组件

Q：如何知道拖拽的是哪个组件？
> 拽事件中使用 `dataTransfer` 对象来携带一些自定义数据~




## SSR渲染

服务器端渲染（SSR）是一种用于在服务器上渲染网页并将完全渲染后的网页发送到客户端显示的技术。它允许服务器生成网页的完整 HTML 标记，包括动态内容，并作为对请求的响应发送给客户端。

`SSR的优势在于它利于搜索引擎优化（SEO）和解决了白屏问题`

react: next.js

vue: nuxt.js


优点：
1. `改善初始加载时间`： SSR 允许服务器向客户端发送完整呈现的 HTML 页面，从而减少客户端所需的处理量。这就改善了初始加载时间，因为用户可以更快地看到完整的页面。
2. `有利于搜索引擎优化`：搜索引擎可以有效地抓取和索引 SSR 页面的内容，因为在初始响应中提供了完全呈现的 HTML。这就提高了搜索引擎的可见性，有助于获得更好的搜索排名。
3. `可访问性`： SSR 可确保禁用 JavaScript 或使用辅助技术的用户可以访问内容。通过在服务器上生成 HTML，SSR 可为所有用户提供可靠、可访问的用户体验。
4. `低带宽环境下的性能`： SSR 减少了客户端需要下载的数据量，因此有利于低带宽或高延迟环境中的用户。这对于移动用户或网络连接速度较慢的用户尤为重要。

缺点：增加了服务器的负载和复杂性，生命周期不全，第三方库不全，学习成本大

客户端渲染：请求一个url => 返回空的首屏html => 首屏请求数据 => 获取首屏数据 => 后端返回首屏数据 => 请求ajax数据，返回， 渲染

服务端渲染：请求一个url  => 获取首屏数据 => 后端返回渲染好的首屏html => 其他ajax请求...


客户端渲染是等js代码下载、加载、解析完成后再请求数据渲染，等待的过程页面是什么都没有的，就是用户看到的白屏。

就是服务端渲染不需要等待js代码下载完成并请求数据，就可以返回一个已有完整数据的首屏页面。






## Node.js

Node.js 是一个开源的、跨平台的 JavaScript 运行时环境。

特点：
1. `异步非阻塞`：采用了非阻塞型I/O机制，在做I/O操作的时候不会造成任何的阻塞，当完成之后，以时间的形式通知执行操作, 能够在单个线程上处理大量并发请求
> 例如在执行了访问数据库的代码之后，将立即转而执行其后面的代码，把数据库返回结果的处理代码放在回调函数中，从而提高了程序的执行效率

2. `事件驱动`：事件驱动就是当进来一个新的请求的时，请求将会被压入一个事件队列中，然后通过一个循环来检测队列中的事件状态变化，如果检测到有状态变化的事件，那么就执行该事件对应的处理代码，一般都是回调函数



Node.js底层的实现包括两个主要组件：
1. `V8引擎`: 这是一个高性能的JavaScript引擎，负责将JavaScript代码编译成机器码并执行。它是Node.js的核心组件，使得Node.js能够运行JavaScript代码。
2. `libuv库`: 这是一个跨平台的库，用于`处理事件循环、异步I/O、文件系统操作`等。它提供了对底层操作系统API的封装，使得Node.js`可以实现非阻塞式的异步操作，从而达到高性能和高并发`的目标。


优点：
1. 处理高并发场景性能更佳
2. 适合I/O密集型应用，值的是应用在运行极限时，CPU占用率仍然比较低，大部分时间是在做 I/O硬盘内存读写操作

因为Nodejs是单线程，带来的缺点有：
1. 不适合CPU密集型应用
2. 只支持单核CPU，不能充分利用CPU
3. 可靠性低，一旦代码某个环节崩溃，整个系统都崩溃


适合应用：
1. `善于I/O，不善于计算`: 因为Nodejs是一个单线程，如果计算（同步）太多，则会阻塞这个线程
    > 用户表单收集系统、后台管理系统、实时交互系统、考试系统、联网软件、高并发量的web应用程序

2. 与 websocket 配合，开发长连接的实时交互应用程序
    > 基于web的多人实时聊天客户端、聊天室、图文直播



### 怎么看 nodejs 可支持高并发？

1. 单线程架构，省去了线程间切换的开销
2. 核心就要在于 `js 引擎的事件循环机制`

结论： `nodejs 是异步非阻塞的，所以能扛住高并发`


- **同步**：在发起一个调用后，在没有得到结果前，该调用不返回，直到调用返回，才往下执行，也就是说调用者等待被调用方返回结果。


- **异步**：在发起一个调用后，调用就直接返回，不等待结果，继续往下执行，而执行的结果是由被调用方通过状态、通知等方式告知调用方，典型的异步编程模型比如 Node.js

- **阻塞**：在等待调用结果时，线程挂起了，不往下执行

- **非阻塞**：与上面相反，当前线程继续往下执行




### Node.js模块

Node.js有哪些全局对象：
1. 真正的全局对象：`process, console, clearInterval、setInterval, clearTimeout、setTimeout, global`
2. 模块级别的全局对象:
    - `__dirname`: 获取当前文件所在的路径，不包括后面的文件名;
    - `__filename`: 获取当前文件所在的路径和文件名称，包括后面的文件名称
    - `module.exports`: module.exports 用于指定一个模块所导出的内容，即可以通过 require() 访问的内容
    - `require`:用于引入模块、 JSON、或本地文件。 



**process** 对象是一个全局变量，提供了有关当前 Node.js进程的信息
1. `process.env`：环境变量，例如通过 `process.env.NODE_ENV` 获取不同环境项目配置信息
2. `process.cwd()`: 返回当前 Node进程执行的目录


**child_process**子进程：使用 `spawn()` 方法可以创建一个新的子进程，执行指定的命令


**Cluster**: 应用部署到多核服务器时，为了充分利用多核 CPU 资源一般启动多个 NodeJS 进程提供服务，这时就会使用到 NodeJS 内置的 Cluster 模块了
> Cluster模块可以创建同时运行的子进程（Worker进程），同时共享同一个端口。每个子进程都有自己的事件循环、内存和V8实例。


**worker_thread多线程**: 允许在一个 Node.js 实例中运行多个应用程序线程。相比创建多个进程更轻量，并且可以共享内存。进程间通过传输 ArrayBuffer 实例或共享 SharedArrayBuffer 实例来做到这一点。
> worker_threads已被证明是充分利用CPU性能的最佳解决方案




**fs（filesystem）**，该模块提供本地文件的读写能力，基本上是`POSIX`文件操作命令的简单包装; 可以说，所有与文件的操作都是通过fs核心模块实现; 
> 对所有文件系统操作提供异步和同步`.sync`两种操作方式
`readFileSync, writeFileSync, appendFile, copyFileSync`



**Buffer**: 在Node应用中，需要处理网络协议、操作数据库、处理图片、接收上传文件等，在网络流和文件的操作中，要处理大量二进制数据，而Buffer就是在内存中开辟一片区域（初次初始化为8KB），用来存放二进制数据
1. I/O操作：通过流的形式，将一个文件的内容读取到另外一个文件
2. 加解密


**流（Stream）**，是一个数据传输手段，是端到端信息交换的一种方式，而且是有顺序的,是`逐块读取数据、处理内容`，用于顺序读取输入或写入输出

> 流，可以理解成是一个管道，比如读取一个文件，常用的方法是从硬盘读取到内存中，在从内存中读取，这种方式对于小文件没问题，但若是大文件，效率就非常低，还有可能内存不足，采用流的方式，就好像给大文件插上一根吸管，持续的一点点读取文件的内容，管道的另一端收到数据，就可以进行处理

分成四个种类：
1. `可写流`：可写入数据的流。例如 `fs.createWriteStream()` 可以使用流将数据写入文件
2. `可读流`： 可读取数据的流。例如`fs.createReadStream()` 可以从文件读取内容
3. `双工流`： 既可读又可写的流。例如 `net.Socket`
4. `转换流`： 可以在数据写入和读取时修改或转换数据的流。例如，在文件压缩操作中，可以向文件写入压缩数据，并从文件中读取解压数据

> 在NodeJS中HTTP服务器模块中，request 是可读流，response 是可写流。还有fs 模块，能同时处理可读和可写文件流

stream的应用场景主要就是处理`IO操作`，而http请求和文件操作都属于IO操作: `get请求返回文件给客户端, 文件操作, 一些打包工具的底层操作`



**EventEmitter**

Node采用了事件驱动机制，而`EventEmitter就是Node实现事件驱动的基础`; 在EventEmitter的基础上，Node几乎所有的模块都继承了这个类，这些模块拥有了自己的事件，可以绑定／触发监听器，实现了异步操作



### 宏任务和微任务

在Node中，同样存在`宏任务和微任务`，与浏览器中的事件循环相似

**微任务对应有：**
1. `next tick queue`：process.nextTick
2. `other queue`：Promise的then回调、queueMicrotask


**宏任务对应有：**
1. `timer queue`：setTimeout、setInterval
2. `poll queue`：IO事件
3. `check queue`：setImmediate
4. `close queue`：close事件

其执行顺序为：`next tick microtask queue` > `other microtask queue` > `timer queue` > `poll queue` > `check queue` > `close queue`



### 文件查找的优先级

缓存的模块优先级最高 > 内置模块 > `绝对路径 / 开头，则从根目录找` > `相对路径 ./ 开头，则从当前require文件相对位置找` > `没有携带后缀，先从js、json、node按顺序查找` > `是目录，则根据 package.json的main属性值决定目录下入口文件，默认情况为 index.js` > 第三方模块



### 中间件（Middleware）

是介于应用系统和系统软件之间的一类软件，它使用系统软件所提供的基础服务（功能），衔接网络上应用系统的各个部分或不同的应用，能够达到资源共享、功能共享的目的

> 在NodeJS中，中间件主要是指`封装http请求细节处理`的方法。例如在express、koa等web框架中，中间件的本质为一个`回调函数`，参数包含请求对象、响应对象和执行下一个中间件的函数，我们可以执行业务逻辑代码，修改请求和响应对象、返回响应数据等操作。


Koa 中间件采用的是`洋葱圈模型`, Koa存在很多第三方的中间件，如`koa-bodyparser、koa-static`等, 都是函数, 会传入两个参数: 
1. ctx ：封装了request 和 response 的变量
2. next ：进入下一个要执行的中间件的函数

在实现中间件时候，单个中间件应该足够简单，职责单一，中间件的代码编写应该高效，必要的时候通过缓存重复获取数据; koa本身比较简洁，但是通过中间件的机制能够实现各种所需要的功能，使得web应用具备良好的可拓展性和组合性



### 如何实现jwt鉴权机制？

`JWT（JSON Web Token）`，本质就是一个字符串书写规范

在目前前后端分离的开发过程中，使用token鉴权机制用于身份验证是最常见的方案：
1. 服务器当验证用户账号和密码正确的时候，给用户颁发一个令牌，这个令牌作为后续用户访问一些接口的凭证
2. 后续访问会根据这个令牌判断用户时候有权限进行访问

Token，分成了三部分，`头部（Header）、载荷（Payload）、签名（Signature）`，并以`.`进行拼接。


如何实现：
1. 生成token: 借助第三方库`jsonwebtoken`，通过jsonwebtoken 的 sign 方法生成一个 token;
2. 校验token：使用 `koa-jwt` 中间件进行验证，方式比较简单
> secret 必须和 sign 时候保持一致; 可以配置接口白名单; 



### 如何实现文件上传？

1. 前端表单组件文件上传：`multipart/form-data`
2. 服务端文件解析：获取上传的文件，获取文件数据后，可以通过fs创建将文件保存到指定目录（可读流通过管道写入可写流）`fs.createWriteStream`



### Node性能如何进行监控以及优化？


nodejs性能衡量指标一般有如下：
1. CPU：CPU负载，CPU使用率; 用来评估系统当前CPU的繁忙程度的量化指标
2. 内存：内存占用率是评判一个系统的内存瓶颈的常见指标， `process.memoryUsage()`
3. 磁盘I/O：内存IO 比 磁盘IO 快非常多，所以使用内存缓存数据是有效的优化方法。常用的工具如 redis、memcached等
4. 网络




### Express vs Koa ?
1. 中间件链接方式：Express 中间件链是基于回调的，有回调地狱问题；而 Koa 的则是用 ES6+ 中的 async/await 来解决异步处理问题，使得代码更加清晰易读。
2. Express 是 NodeJS 的一个 Web 框架。它通过为 Node 的 req 和 res 对象添加有用的方法和属性来增强其功能；Koa 是 NodeJS 的一个中间件框架。Koa 使用自己的上下文（ctx）替换或提取 Node 的 req 和 res 对象属性。
3. 更加轻量 Koa 比 Express 更轻量级。Koa 不像 Express 那样包含路由器或视图引擎模块。



### 洋葱模型？

洋葱模型的核心思想是，Koa 中间件的执行顺序和处理流程类似于一个洋葱，请求在经过多个中间件处理时，会像剥洋葱一样，`从外向内逐步执行，然后再从内向外逐步返回结果`。每个中间件都有机会在请求进入和离开时进行处理，同时也可以对请求进行修改或添加新的功能。

中间件函数有两个参数第一个是`上下文`，第二个是 `next`，在中间件函数执行过程中，若遇到 next() ，那么就会进入到下一个中间件中执行，下一个中间执行完成后，在返回上一个中间件执行 next() 后面的方法，这便是中间件的执行逻辑。





### PM2

pm2 是 process manager，进程管理，它是第二个大版本，和前一个版本差异很大，所以叫 pm2；pm2 的主要功能就是`进程管理、日志管理、负载均衡、性能监控`这些。

- 进程管理的话就是可以手动启动、重启、停止某个进程，而且崩溃了会自动重启，也可以定时自动重启。

- 负载均衡: node 应用是单进程的，而为了充分利用多核 cpu，我们会使用多进程来提高性能。node 提供的 cluster 模块就是做这个的，pm2 就是基于这个实现了负载均衡。








## Nginx

Nginx 是一个轻量级的 HTTP 服务器，采用`事件驱动、异步非阻塞`处理方式的服务器，它具有极好的 IO 性能，常用于 HTTP服务器（包含动静分离）、正向代理、反向代理、负载均衡 等等.


Nginx 和 Node.js 在很多方面是类似的，例如都是 HTTP 服务器、事件驱动、异步非阻塞等，且 Nginx 的拥有的功能，也可以使用 Node.js 去实现，但它们的使用场景是不同的，`Nginx 擅长于底层服务器端资源的处理（静态资源处理转发、反向代理，负载均衡等），Node.js 更擅长上层具体业务逻辑的处理.`

Nginx 使用了`进程池 + 单线程`的工作模式。






## HTTP


### Http缓存


1. 减少了冗余的数据传输，节省了网费。
2. 缓解了服务器的压力， 大大提高了网站的性能
3. 加快了客户端加载网页的速度


**强缓存+协商缓存**

1. 第一次请求资源时，服务器返回资源，并在respone header头中回传资源的缓存参数；

2. 第二次请求时，浏览器判断这些请求参数，命中`强缓存`就直接200，否则就把请求参数加到request header头中传给服务器，看是否命中`协商缓存`，命中则返回304，否则服务器会返回新的资源。


- **强缓存**

`Cache-Control的max-age没有过期`或者`Expires的缓存时间没有过期`

那么就会直接使用浏览器的缓存数据，不会再向服务器发送任何请求。强制缓存生效时，http状态码为`200`。

- **协商缓存**

`当第一次请求时服务器返回的响应头中没有Cache-Control和Expires`或者`Cache-Control和Expires过期`, 或者`它的属性设置为no-cache`

1. 那么浏览器第二次请求时就会与服务器进行协商，与服务器端对比判断资源是否进行了修改更新。如果服务器端的资源没有修改，那么就会返回`304`状态码，告诉浏览器可以使用缓存中的数据，这样就减少了服务器的数据传输压力。

2. 如果数据有更新就会返回200状态码，服务器就会返回更新后的资源并且将缓存信息一起返回。

跟协商缓存相关的header头属性有: `ETag/If-Not-Match 、Last-Modified/If-Modified-Since`, 

**协商缓存的执行流程是这样的：**
1. 当浏览器第一次向服务器发送请求时，会在响应头中返回协商缓存的头属性：`ETag和Last-Modified`,其中**ETag返回的是一个hash值**，`Last-Modified`返回的是GMT格式的最后修改时间;
2. 然后浏览器在第二次发送请求的时候，会在请求头中带上与ETag对应的`If-Not-Match，其值就是响应头中返回的ETag的值`，Last-Modified对应的`If-Modified-Since`;
3. 服务器在接收到这两个参数后会做比较，如果返回的是304状态码，则说明请求的资源没有修改，浏览器可以直接在缓存中取数据，否则，服务器会直接返回数据。


`ETag/If-Not-Match`是在`HTTP/1.1`出现的，主要是解决以下问题：
1. ``Last-Modified标注的最后修改只能精确到秒级``，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间
2. 如果某些文件被修改了，但是内容并没有任何变化，而Last-Modified却改变了，导致文件没法使用缓存
3. 有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形


### Cache 和 Cookie 异同？

> Cache 和 Cookie 都是服务器发给客户端并存储的数据，你能比较一下两者的异同吗？

- 相同点：都会保存到浏览器中，并可以设置过期时间。

- 不同点：
1. Cookie 会随请求报文发送到服务器，而 Cache 不会，但验证资源是否过期。
2. Cookie 在浏览器可以通过脚本获取（如果 cookie 没有设置 HttpOnly），Cache 则无法在浏览器中获取（出于安全原因）。
3. Cookie 通过响应报文的 `Set-Cookie` 字段获得，cache 缓存的是完整的报文。
4. 用途不同。`Cookie 常用于身份识别，Cache 则是由浏览器管理`，用于节省带宽和加快响应速度。
5. Cookie 的 max-age 是从浏览器拿到响应报文时开始计算的，而 Cache 的 max-age 是从响应报文的生成时间（Date 头字段）开始计算。


### 强制刷新会什么会返回200？

> 即使有“Last-modified”和“ETag”，强制刷新（Ctrl+F5）也能够从服务器获取最新数据（返回 200 而不是 304），观察请求头和响应头，解释原因。

`强制刷新后请求头中 没有了 If-None-Match ，而且 Cache-Control: no-cache`；没有条件请求头，那么服务器就无法处理缓存，就只能返回最新的数据。



### DNS域名系统

在 TCP/IP 协议中使用 IP 地址来标识计算机，数字形式的地址对于计算机来说是方便了，但对于人类来说却既难以记忆又难以输入。

于是域名系统（Domain Name System）出现了，`用域名来作为 IP 地址的等价替代`。

域名解析：通过域名，映射它的真实ip地址。

``` js
www.bidu.com
// www 主机名
// baidu 二级域名
// com 顶级域名
```


域名解析流程，如访问`www.baidu.com`：
1. 访问`根域名服务器`，它会告诉你`com`顶级域名服务器的地址；
2. 访问com`顶级域名服务器`，它再告诉你`apple.com`域名服务器的地址；
3. 最后访问apple.com`权威域名服务器`，就得到了`www.apple.com`的地址。


浏览器输入一个域名，完整的解析流程：

`浏览器缓存 -> 操作系统缓存 -> hosts文件 -> 非权威域名服务器 -> 根域名服务器 -> 顶级域名服务器 -> 二级域名服务器 -> 权威域名服务器。`



### 从输入url,发生了什么？

- DNS解析：输入域名，域名解析成ip地址；可能解析成CDN的ip地址（缓存，直接响应）；

- TCP三次握手建立连接

- 浏览器向服务端发送请求报文：
    - HTTP 请求经过无数的路由器、网关、代理，最后到达服务器
    - 负载均衡：它会先访问系统里的缓存服务器，它们的作用与 CDN 类似，减轻后端应用服务器的压力；
    - 如果缓存服务器里也没有，那么负载均衡设备就要把请求转发给应用服务器，它们又会再访问后面的 MySQL、MongoDB 等数据库服务，然后把执行的结果返给负载均衡设备，同时也可能给缓存服务器里也放一份。
    - 按原路返回，还是要经过路由器、网关、代理。如果这个资源允许缓存，经过 CDN 的时候会进行缓存。

- 服务器收到报文后解析报文，处理请求，生成响应报文；发送给浏览器；

- 浏览器解析报文，渲染；

**具体流程：**
1. DNS解析：判断url是否合法；没问题则依次判断本地DNS服服务器、操作系统、hosts文件是否有缓存；无则再依次向根域名服务器、顶级域名服务器、权威域名服务器获取完整域名ip地址；
    - 用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求。

2. 通过TCP/IP协议栈获取目的主机的MAC地址；
3. TCP三次握手建立连接：
    - 首先客户端向服务器发送一个 `SYN 连接请求报文段`和一个`随机序号`，
    - 服务端接收到请求后向服务器端发送一个 `SYN ACK报文段`，确认连接请求，并且也向客户端发送一个`随机序号`。
    - 客户端接收服务器的确认应答后，进入连接建立的状态，同时向服务器也发送一个`ACK 确认报文段`；服务器端接收到确认后，也进入连接建立状态，此时双方的连接就建立起来了。

4. HTTPS握手：如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程
    - 首先由客户端向服务器端发送使用的`协议的版本号`、一个`随机数`和可以使用的`加密方法`;
    - 服务器端收到后，确认加密的方法，也向客户端发送一个`随机数`和自己的`数字证书`;
    - 客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个`随机数`，并`使用证书中的公钥对随机数加密`，然后发送给服务器端，并且还会提供一个前面所有内容的 `hash 值`供服务器端检验;
    - 服务器端接收后，使用自己的`私钥对数据解密`，同时向客户端发送一个前面所有内容的 `hash 值`供客户端检验；
    
这个时候双方都有了`三个随机数`，按照之前所约定的加密方法，`使用这三个随机数生成一把秘钥`，以后双方通信前，就`使用这个秘钥对数据进行加密`后再传输。

5. 浏览器向服务端发送请求报文：路由器、网关、代理 => 后端缓存服务器、应用服务器，拿到数据；原路返回，前端CDN缓存；

6. 页面渲染：HTMLDom + CSSDom => renderDom；布局；绘制；如果遇到 script 标签，则判端是否含有 defer 或者 async 属性，要不然 script 的加载和执行会造成页面的渲染的阻塞；

7. TCP四次挥手：
    - 若客户端认为数据发送完成，则它需要向服务端发送连接释放请求；
    - 服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态；
    - 服务端数据发送完毕后会向客户端发送连接释放请求，然后服务端便进入 LAST-ACK 状态;
    - 客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态；








### 三次握手

> 在真正的读写操作之前，客户端与服务器端之间必须建立一个连接，连接的建立依靠三次握手

握手过程中使用了 TCP 的标志（flag）：`SYN`（synchronize:同步） 和 `ACK`（acknowledgement:承认,应答）。


**第一次握手**：起初两端都处于`关闭状态`，客户端将`标志位SYN`置为1，随机产生一个`初始化序列号seq=J`，并将该数据包发送给服务端，客户端进入`同步已发送状态`，等待服务端确认；服务端被动打开连接，处于`LISTEN状态`；


**第二次握手**: 服务端收到连接请求报文段后，如同意建立连接，则向客户端发送确认报文：`SYN=1，ACK=1，确认号ack=J+1，初始序号seq=K`，服务端进程进入`同步已收到状态`；


**第三次握手**: 客户端收到服务端的确认后，要向服务端给出确认报文段: `ACK=1，确认号ack=K+1，序号seq=J+1`（初始为seq=J，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。TCP连接已经建立，客户端进入`已建立连接状态`。当服务端收到客户端的确认后，也进入`已建立连接状态`。


### 为什么服务端还要发送一次确认呢？可以二次握手吗？

1. 确认双方的接收与发送能力是否正常：

- `第一次握手`：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
- `第二次握手`：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
- `第三次握手`：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。
因此，`需要三次握手才能确认双方的接收与发送能力是否正常`。

2. 指定自己的`初始化序列号seq`(Initial Sequence Number)，为后面的可靠传送做准备。

3. 如果是 `https` 协议的话，三次握手这个过程，还会进行`数字证书的验证以及加密密钥的生成`。


### 什么是半连接队列？

服务器第一次收到客户端的 SYN 之后，就会处于 `同步已收到状态`，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为`半连接队列`。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。


### 三次握手过程中可以携带数据吗？

第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。

假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。


### 四次挥手

当读写操作完成后，双方不再需要这个连接时可以释放这个连接，而释放则需要四次握手。

**第一次挥手**: 刚开始双方都处于 establised 状态，若客户端 A 认为数据发送完成，则它需要向服务端 B 发送连接释放请求；随后客户端发送一个 FIN 报文，`报文中会指定一个序列号`；此时客户端处于 FIN_WAIT1 状态。

**第二次挥手**：服务端收到 FIN 之后，会发送 ACK 报文，且`把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了`，此时服务端处于 CLOSE_WAIT 状态。
> 此时表明 A 到 B 的连接已经释放，不再接收 A 发的数据了。但是因为 TCP 连接是双向的，所以 B 仍旧可以发送数据给 A。

**第三次挥手**: 如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且`指定一个序列号`。此时服务端处于 LAST_ACK（最后确认）状态。

**第四次挥手**: 客户端收到 FIN 之后，一样`发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值`，此时客户端处于 TIME_WAIT（时间等待） 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态；

> 服务端收到 ACK 报文之后，就关闭连接了，处于 CLOSED 状态。



### 第四次挥手客户端有一个 TIME_WAIT 状态，为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭？

`要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端`，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。

`至于 TIME_WAIT 持续的时间至少是一个报文的来回时间`：2MSL（MSL 最长报文段寿命Maximum Segment Lifetime）。如果过了 2MSL 没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态。


### 为什么连接的时候是三次握手，关闭的时候却是四次握手？

因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中`ACK报文是用来应答的，SYN报文是用来同步的`。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。`只有等到我Server端所有的报文都发送完了，我才能发送FIN报文`，因此不能一起发送。故需要四步握手。



### HTTP报文结构

纯文本”的协议，所以头数据都是 ASCII 码的文本

HTTP 协议的请求报文和响应报文的结构: `起始行 / 头部 / 空行 / 实体`


- **请求行**

请求报文里的起始行也就是请求行（request line），它简要地描述了客户端想要如何操作服务器端的资源。

`GET / HTTP/1.1`: “GET”是请求方法；“/”是请求目标；“HTTP/1.1”是版本号


- **状态行**

响应报文里的起始行叫状态行（status line），意思是服务器响应的状态。

`HTTP/1.1 200 OK`: 协议版本号：1.1，状态码：200，说明：OK



- **状态码**
1. 1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
2. 2××：成功，服务器收到并成功处理了客户端的请求, 报文已经收到并被正确处理；
    - `206 Partial Content` 是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现。
3. 3××：重定向，资源位置发生变动，需要客户端重新发送请求；
    - 301：永久重定向，含义是此次请求的资源已经不存在了
    - 302：临时重定向，意思是请求的资源还在，但需要暂时用另一个 URI 来访问
    - 304 Not Modified：协商缓存重定向, 表示资源未修改，用于缓存控制
4. 4××：客户端错误，请求报文有误，服务器无法处理；
5. 5××：服务器错误，服务器在处理请求时内部发生了错误。



- **头部字段**

请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头

头部字段是 `key-value` 的形式，key 和 value 之间用“:”分隔, 用 `CRLF 换行`表示字段结束


常用头部字段:
1. 通用字段：在请求头和响应头里都可以出现；`Date, `
2. 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件; `Host,User-Agent, `
3. 响应字段：仅能出现在响应头里，补充说明响应报文的信息；`Server`
4. 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。`Content-Length`



- **实体**

MIME 是一个很大的标准规范，HTTP 只取了其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的MIME type。

MIME type 常用类别：`text、image、application/json...`

Encoding type 常用类别：`gzip...`：告诉数据是用的什么编码格式

``` js
Accept: text/html,application/xml,image/webp,image/png // 告诉服务器希望接收什么样的数据
Content-Type: text/html // 务器会在响应报文里用头字段 Content-Type 告诉实体数据的真实类型
Accept-Encoding: gzip, deflate, br // 客户端支持的压缩格式
Content-Encoding: gzip // 实际使用的压缩格式放在响应头字段
Accept-Language: zh-CN, zh, en
```

- **OPTIONS请求**

对那些可能对服务器数据产生副作用的 HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个`预检请求`（preflight request），从而`获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求`。



### HTTP传输大文件的方法

1. **数据压缩**

通常浏览器在发送请求时都会带着“Accept-Encoding”头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进“Content-Encoding”响应头里，再把原数据压缩后发给浏览器。

2. **分块传输**

在响应报文里用头字段“`Transfer-Encoding: chunked`”来表示分块传输，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。

> `Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的`，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked）。


3. **范围请求**

允许客户端在请求头里使用专用字段来表示只获取文件的一部分。

服务器在响应头里使用字段`Accept-Ranges: bytes`则表示支持范围请求。如果服务器发送Accept-Ranges: none，或不发送“Accept-Ranges”字段，就表示不支持范围请求。

``` sh
###### 发送的请求报文 ########
GET /16-2 HTTP/1.1
Host: www.chrono.com
Range: bytes=0-31 # 获取了文件的前 32 个字节

###### 返回的响应报文 ########
HTTP/1.1 206 Partial Content
Content-Length: 32
Accept-Ranges: bytes
Content-Range: bytes 0-31/96 # 返回文件的前 32 个字节，并返回文件总长度 96 字节
```

多段下载、断点续传也是基于它实现的：

1. 先发个 HEAD，看服务器是否支持范围请求，同时获取文件的大小；
2. 开 N 个线程，每个线程使用 Range 字段划分出各自负责下载的片段，发请求传输数据；
3. 下载意外中断也不怕，不必重头再来一遍，只要根据上次的下载记录，用 Range 请求剩下的那一部分就可以了。


4. **多段数据**

范围请求一次只获取一个片段，其实它还支持在 Range 头里使用多个“x-y”，一次性获取多个片段数据

MIME 类型：`multipart/byteranges`，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数`boundary=xxx`给出段之间的分隔标记。

``` sh
GET /16-2 HTTP/1.1
Host: www.chrono.com
Range: bytes=0-9, 20-29  # 发出两个范围的请求
```


### HTTP的连接管理

- 短连接：短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。

- 长连接：`Connection：keep-alive`

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式：
1. 使用`keepalive_timeout`指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
2. 使用`keepalive_requests`指令，设置长连接上可发送的最大请求次数。



### 队头阻塞

因为 HTTP 规定报文必须是“一发一收”，这就形成了一个`先进先出的“串行”队列`。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。

如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。

解决：
1. 并发连接（concurrent connections）：同时对一个域名发起多个长连接，用数量来解决质量的问题。
2. 域名分片（domain sharding）：HTTP 协议和浏览器会限制并发连接数量，那就多开几个域名，这些域名都指向同一台服务器，这样实际长连接的数量就又上去了。还是用数量来解决质量的思路。


### DDoS攻击

利用 HTTP 长连接特性对服务器发起大量请求，导致服务器最终耗尽资源“拒绝服务”，这就是常说的DDoS。


### Cookie 的工作过程

1. 当用户通过浏览器第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是key=value，然后放进 Set-Cookie 字段里，随着`响应报文一同发给浏览器`。

2. 浏览器收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。




### 爬虫

一种可以自动访问 Web 资源的应用程序。

绝大多数爬虫是由各大搜索引擎“放”出来的，抓取网页存入庞大的数据库，再建立关键字索引，这样我们才能够在搜索引擎中快速地搜索到互联网角落里的页面。
> 但它会过度消耗网络资源，占用服务器和带宽，影响网站对真实数据的分析，甚至导致敏感信息泄漏。所以，又出现了“反爬虫”技术，通过各种手段来限制爬虫。


### TCP/IP 网络分层模型

TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。

TCP/IP 协议总共有四层: **链接层 》 网络层 》 传输层 》 应用层** （从下往上）

1. `第一层叫链接层（link layer）`，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用`MAC地址（局域网地址）来标记网络上的设备`，所以有时候也叫 MAC 层。
2. `第二层叫网际层或者网络互连层（internet layer），IP 协议就处在这一层`。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，`用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络`，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。
3. 第三层叫`传输层（transport layer）`，这个层次协议的职责是`保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次`，另外还有它的一个“小伙伴”UDP。
    - TCP 的数据是连续的字节流，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。
    
4. 协议栈的第四层叫`应用层（application layer）`，由于下面的三层把基础打得非常好，所以在这一层就“百花齐放”了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 `HTTP`。


### OSI 网络分层模型

从下往上：物理层 《 数据链路层 《 网络层 《 传输层 《 `会话层 《 表示层 《 应用层`



所谓的`四层负载均衡`就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。

所谓的`七层负载均衡`就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。


### TCP/IP 协议栈的工作方式

HTTP 协议的`传输过程`通过协议栈`逐层向下`，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。

`接收数据`则是相反的操作，`从下往上穿过协议栈`，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据。




### HTTP协议的优点和缺点

优点：
1. `支持客户端/服务器模式`
2. `简单快速`：客户向服务器请求服务时，只需传送请求方法和路径。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。
3. `无连接`：无连接就是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。
4. `无状态`：HTTP 协议是无状态协议，这里的状态是指通信过程的上下文信息。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能会导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就比较快。
5. `灵活`：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。

缺点：
1. 无状态：不会存储信息；
2. 明文传输：不安全；



### HTTPS

HTTPS 名字里的“S”，它把 HTTP 下层的传输协议由 TCP/IP 换成了 SSL/TLS，由“HTTP over TCP/IP”变成了 ``HTTP over SSL/TLS`` ，让 HTTP 运行在了安全的 SSL/TLS 协议上。

HTTP = `HTTP + TCP + IP + MAC`

HTTPS = `HTTP + SSL/TLS + TCP + IP +MAC`



**对称加密**: 指加密和解密时使用的密钥都是同一个，是“对称”的。只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。

**非对称加密**（也叫公钥加密算法）: 它有两个密钥，一个叫公钥（public key），一个叫私钥（private key）。两个密钥是不同的，“不对称”，公钥可以公开给任何人使用，而私钥必须严格保密。`公钥加密后只能用私钥解密`

网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。



**摘要算法**近似地理解成一种特殊的压缩算法，它能够`把任意长度的数据“压缩”成固定长度、而且独一无二的“摘要”字符串`，就好像是给这段数据生成了一个数字“指纹”；这也是一种特殊的“单向”加密算法，它只有算法，没有密钥，`加密后的数据无法解密`，不能从摘要逆推出原文。

> `MD5、SHA-2`，它们就是最常用的两个摘要算法，能够生成 16 字节和 20 字节长度的数字摘要




**数字签名**：数字签名的原理其实很简单，就是把公钥私钥的用法反过来，之前是公钥加密、私钥解密，现在是`私钥加密、公钥解密`。
> 私钥只加密原文的摘要，这样运算量就小的多，而且得到的数字签名也很小，方便保管和传输。

签名和公钥一样完全公开，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，拿到摘要后，再比对原文验证完整性，就可以像签署文件一样证明消息确实是你发的。


1. 摘要算法用来实现完整性，能够为数据生成独一无二的“指纹”，常用的算法是 SHA-2；
2. 数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认；
3. 公钥的分发需要使用数字证书，必须由 CA 的信任链来验证，否则就是不可信的；
4. 作为信任链的源头 CA 有时也会不可信，解决办法有 CRL、OCSP，还有终止信任。



### HTTP与HTTPS区别

1. HTTPS协议需要CA证书，费用较高；而HTTP协议不需要；
2. HTTP协议是超文本传输协议，信息是明文传输的，HTTPS则是具有安全性的SSL加密传输协议；
3. 使用不同的连接方式，端口也不同，HTTP协议端口是80，HTTPS协议端口是443；
4. HTTP协议连接很简单，是无状态的；`HTTPS协议是有SSL和HTTP协议构建的可进行加密传输、身份认证的网络协议`，比HTTP更加安全。


### HTTP/2的改造

- **头部压缩**: HTTP/2 并没有使用传统的压缩算法，而是开发了专门的“`HPACK`”算法：用`索引号表示重复的字符串`，采用`哈夫曼编码来压缩整数和字符串`，可以达到50%~90%的高压缩率。

- **二进制格式**: HTTP/1 里是纯文本形式的报文，HTTP/2 不再使用肉眼可见的 ASCII 码，而是向下层的 TCP/IP 协议“靠拢”，全面采用二进制格式。`二进制帧`

- **数据流**: HTTP/2 为此定义了一个流（`Stream`）的概念, 它是二进制帧的双向传输序列，同一个消息往返的帧会分配一个`唯一的流 ID`。在里面流动的是一串有先后顺序的`数据帧`，这些数据帧按照次序组装起来就是 HTTP/1 里的请求报文和响应报文。

> 多个请求 / 响应之间没有了顺序关系，不需要排队等待，也就`不会再出现“队头阻塞”问题`，降低了延迟，大幅度提高了连接的利用率

接收方使用它就可以从乱序的帧里识别出具有相同流 ID 的帧序列，按顺序组装起来就实现了虚拟的“流”。


- **服务端推送**： HTTP/2 还在一定程度上改变了传统的“请求 - 应答”工作模式，服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息。


HTTP/2协议栈：`HTTP > HPack/Stream > TLS > TCP > IP > MAC`



### 常见的攻击方式

- `CSRF，跨站请求伪造`，是指攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。
    1. 攻击者将支付的接口请求隐藏在 img 标签内，在加载这个标签时，浏览器会自动发起 img 的资源请求
    2. 访问页面后，表单会自动提交，相当于模拟用户完成了一次 POST 操作。
    3. 在论坛中发布的图片中嵌入恶意链接，或者以广告的形式诱导用户中招

解决方案：设置 Cookie 中的 SameSite 属性解决: `Strict：浏览器完全禁止第三方拿到 Cookie`; 同源策略，token认证；其他属性：Lax / None

- `XSS 是跨站脚本攻击`（Cross Site Scripting），为了与 CSS 区别开来，故简称 XSS。往页面恶意的注入脚代码本。当用户浏览该页时，嵌入其中的 Script 代码会被执行，从而达到恶意攻击用户的目的。

解决方案：过滤特殊字符，或对特定字符进行编译转码；对重要的 cookie 设置 `httpOnly`

- `DDoS 攻击`: 分布式拒绝服务攻击（Distributed Denial of Service Attack），有时候也叫“洪水攻击”。

黑客会控制许多“僵尸”计算机，向目标服务器发起大量无效请求。因为服务器无法区分正常用户和黑客，只能“照单全收”，这样就挤占了正常用户所应有的资源。

方案：`检测技术`就是检测网站是否正在遭受 DDoS 攻击，而`清洗技术`就是清洗掉异常流量。




### CDN

CDN（Content Delivery Network 或 Content Distribution Network），中文名叫“内容分发网络”。

CDN 就是专门为解决“长距离”上网络访问速度慢而诞生的一种网络应用服务。

CDN 的最核心原则是“就近访问”, 


### HTTP 1.0和 HTTP 1.1 的区别

1. `http1.0 默认使用非持久连接，而 http1.1 默认使用持久连接`。http1.1 通过使用持久连接来使多个 http 请求复用同一个 TCP 连接，以此来避免使用非持久连接时每次需要建立连接的时延。

2. 在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 `range` 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

3. 在 http1.0 中主要使用 header 里的 If-Modified-Since、Expires 来做为缓存判断的标准，http1.1 则引入了更多的缓存控制策略，例如 `Etag`、If-Unmodified-Since、If-Match、`If-None-Match` 等更多可供选择的缓存头来控制缓存策略。

4. http1.1 相对于 http1.0 还新增了很多请求方法，如 PUT、HEAD、OPTIONS 等。




### http2的多路复用为什么会解决队头阻塞的问题？

在传统的HTTP/1.1中，由于每个请求都需要在单独的TCP连接中按顺序发送和接收，因此如果一个请求因为某种原因被阻塞（例如，等待服务器响应或网络拥塞），那么后续的所有请求都会受到影响，无法并行处理。这种阻塞现象被称为`队头阻塞`。

在HTTP/2中，引入了`多路复用`的概念，`它允许在同一个TCP连接中并行发送和接收多个请求和响应`。这是通过使用`帧（Frame）`作为通信的基本单位来实现的。`每个请求或响应都被拆分成多个帧，并在单个TCP连接中乱序发送。每个帧都有一个唯一的标识符，这样接收端就可以根据标识符重新组装消息，确保消息的顺序正确`。

由于HTTP/2使用了多路复用技术，`当一个请求被阻塞时，其他请求可以继续在相同的TCP连接中发送和接收`。这样，即使某个请求因为某种原因被阻塞，也不会影响到其他请求的处理。因此，队头阻塞的问题得到了解决。




### http2 下服务器主动推送和WebSocket有什么区别？

1. 协议和技术基础:
- HTTP/2 服务器推送: `HTTP/2 服务器推送是基于 HTTP/2 协议的一种机制`，它允许服务器在客户端请求资源时主动推送额外的资源给客户端。推送的资源通常是与客户端请求的资源相关联的其他资源，从而提高页面加载速度。
- WebSocket: `WebSocket 是一种独立的协议`，它建立在 TCP 上，并提供了全双工的通信通道，允许客户端和服务器之间进行实时的双向数据传输。与 HTTP/2 服务器推送不同，WebSocket 不依赖于 HTTP 协议，而是有自己的协议标准。

2. 使用场景:
- HTTP/2 服务器推送: `主要用于优化 Web 页面加载速度`。服务器可以根据客户端请求的资源，提前将可能需要的其他资源推送给客户端，从而减少客户端的等待时间，加快页面加载速度。
- WebSocket: `主要用于实时通信`，例如在线聊天、实时数据更新等场景。WebSocket 提供了一个持久的连接通道，允许客户端和服务器之间双向实时通信，而不需要客户端发起新的 HTTP 请求。

3. 连接机制:
- HTTP/2 服务器推送: 服务器推送是基于 HTTP/2 的单向通信机制。`客户端发起一个请求，服务器可以通过推送响应来发送额外的资源，但客户端不能直接在同一个连接上向服务器发送数据（静态资源）。`
- WebSocket: `WebSocket 提供了一个双向通信的持久连接`。客户端和服务器之间可以自由地发送和接收数据，而不需要依赖于 HTTP 请求-响应周期。




### 浏览器渲染优化方案

1. `减少 HTTP 请求`：合并 CSS 和 JavaScript 文件、使用 CSS Sprites 雪碧图、图片懒加载/按需加载。

2. `优化资源加载`：使用 CDN 加载静态资源；js使用异步加载（async 和 defer）加载 JavaScript 脚本，提高页面加载速度。

3. `使用缓存`：启用浏览器缓存，使用合适的缓存策略。使用服务端缓存，如使用缓存服务器、CDN 缓存等。

4. `DOM 操作优化`：减少 DOM 操作，尽量在 JavaScript 中减少对 DOM 的访问和修改。使用事件委托来减少事件处理器的数量，提高性能。

5. `CSS 和样式优化`：避免使用昂贵的 CSS 选择器，如后代选择器和通配符选择器。使用 CSS3 动画代替 JavaScript 动画，以利用硬件加速。使用 CSS3 Transform 和 CSS3 Transition 来优化动画效果。

6. `JavaScript 优化`：避免使用全局变量，使用局部变量或模块化的方式来管理变量。尽量减少 JavaScript 的执行时间，避免长时间的脚本执行。使用事件委托来优化事件处理，减少事件处理器的数量。

7. `图像优化`：使用适当的图像格式，如 PNG、JPEG、WebP 等。使用适当的图像尺寸和质量，避免图像过大导致加载缓慢。

8. `响应式设计和移动优化`：使用响应式设计来适配不同设备和屏幕大小。优化移动端页面加载速度，减少不必要的资源加载和功能。

9. `性能监控和分析`：使用性能分析工具和浏览器开发者工具来检查和分析网页性能问题。监控网站性能指标，如页面加载时间、资源加载时间、渲染时间等，及时发现和解决性能问题。





## 其他



### 小程序与普通网页开发的区别

网页开发中渲染线程和 JavaScript 线程是互斥 的。即这两个线程不能够穿插执行，必须串行。当其中一个线程执行时，另一个线程只能挂起等待。这也是 JavaScript线程占用主线程时间过长，可能会导致页面失去响应 的原因。

而在小程序中，二者是分开的，分别运行在不同的线程中，即`渲染线程和逻辑线程`。
> 渲染线程使用 WebView 进行 UI 的渲染呈现，逻辑层是用 JavaScript 引擎运行逻辑代码; 小程序的渲染层和逻辑层之间的通信并不是直接传递数据或事件，而是由 Native(微信客户端) 作为中间媒介进行转发。逻辑层发送网络请求也是经由 Native 转发。逻辑层运行在 JSCore 中，并没有一个完整浏览器对象，因而缺少相关的DOM API和BOM API。

​网页开发者需要面对的环境是各式各样的浏览器，PC 端需要面对 IE、Chrome、QQ浏览器等，在移动端需要面对Safari、Chrome以及 iOS、Android 系统中的各式 WebView 。而小程序开发过程中需要面对的是两大操作系统 iOS 和 Android 的微信客户端，以及用于辅助开发的小程序开发者工具



### npm vs yarn vs pnpm 区别？

npm、yarn和pnpm都是用于Node.js项目的包管理工具，它们都有一些共同点，如安装、更新和管理项目的依赖项。

- npm: 嵌套结构的依赖
1. 依赖包重复安装
2. 嵌套层级太深


- yarn: 扁平化目录结构

yarn 虽然在 npm 之上做出了一定的创新和相应的改进，但是在依赖包管理方式上还是借鉴的 npm 的扁平化 node_modules 方式，并没有解决 npm 相应的痛点。


- pnpm 在依赖包管理方式上完全舍弃了 npm 的那一套，利用符号链接的方式重新设计了 node_modules 的结构来处理扁平化带来的问题。


1. `安装速度和性能`：pnpm通常被认为是最快的，因为它采用了`只下载必需的模块`的方法，而不是下载整个依赖树。此外，`pnpm还可以并行下载模块`，从而进一步提高下载速度。yarn也使用并行安装和缓存机制来提高安装速度，尤其是当之前已经安装过某个软件包时，yarn会从缓存中获取，而不是重新下载。相比之下，npm按照队列依次安装每个包，安装速度可能较慢。

2. `磁盘空间占用`：由于pnpm只下载必需的模块，并且`使用硬链接来减少空间占用`，因此它的磁盘空间占用通常比npm和yarn小。yarn也会缓存已安装的包，从而避免重复下载，但它不会像pnpm那样使用硬链接。`npm则会为每个安装的包创建一个新的目录，这可能导致磁盘空间占用较大`。

3. `兼容性和可靠性`：npm是Node.js的官方包管理器，因此它具有最好的兼容性。yarn和pnpm都与npm兼容，但在使用旧版本的Node.js时可能会遇到一些问题。yarn被认为比npm和pnpm更可靠，因为它使用了`多线程下载和安装`，减少了下载和安装失败的风险。此外，yarn还使用锁定文件（如yarn.lock）来确保安装的模块与项目的依赖项相匹配，这也有助于提高可靠性。

4. `功能和扩展性`：yarn提供了一些额外的功能，如缓存、自动解析和自动重试等，这些功能可以提高开发效率。npm和pnpm也有一些额外的功能，但它们的功能不如yarn丰富。此外，yarn和pnpm都支持插件系统，可以通过安装插件来扩展其功能。











### 一次请求大量数据怎么优化，数据多导致渲染慢怎么优化?

1. 数据分片处理, 分页
2. 虚拟列表



### 从页面 A 打开一个新页面 B，B 页面关闭后，如何通知 A 页面？

[https://mp.weixin.qq.com/s/VfZuyFDDkxHWADl443KFKw](https://mp.weixin.qq.com/s/VfZuyFDDkxHWADl443KFKw)

方案：postmessage、localStorage（需同源）、WebSocket。。。

`onbeforeunload`: 在即将离开当前页面(刷新或关闭)时执行
> 页面正常关闭时，会先执行 window.onbeforeunload ，然后执行 window.onunload ，我们可以在这两个方法里向 A 页面通信





### 衍生：B 页面意外崩溃，又该如何通知 A 页面？

> Service Worker 有自己独立的工作线程，与网页区分开，网页崩溃了，Service Worker 一般情况下不会崩溃；Service Worker 生命周期一般要比网页还要长，可以用来监控网页的状态；网页可以通过 `navigator.serviceWorker.controller.postMessage` API 向掌管自己的 SW 发送消息

```
B 页面加载后，通过 postMessage API 每 5s 给 sw 发送一个心跳，表示自己的在线，sw 将在线的网页登记下来，更新登记时间；
B 页面在 beforeunload 时，通过 postMessage API 告知自己已经正常关闭，sw 将登记的网页清除；
如果 B页面在运行的过程中 crash 了，sw 中的 running 状态将不会被清除，更新时间停留在奔溃前的最后一次心跳；
A 页面 Service Worker 每 10s 查看一遍登记中的网页，发现登记时间已经超出了一定时间（比如 15s）即可判定该网页 crash 了。
```


### 后端一次性返回10万条数据给你，你如何处理？

1. 使用定时器分组分批分堆依次渲染（定时加载、分堆思想）
2. 使用 requestAnimationFrame 替代定时器去做渲染: 优化页面卡顿，解决定时器太多资源浪费
3. 搭配分页组件，前端进行分页；或者滚动触底加载；
4. 使用无限加载/虚拟列表进行展示
5. 开启多线程Web Worker进行操作



### 当页面使用级联选择器，数据比较多时页面会卡顿，怎么优化？

当页面使用级联选择器（如常见的省市区选择器）并且数据较多时，确实可能会出现页面卡顿的情况。这种情况通常是由于浏览器渲染大量DOM元素、执行大量JavaScript代码或处理大量数据导致的。

1. 虚拟滚动（Virtual Scrolling）：

虚拟滚动是一种技术，`它只渲染可视区域内的元素，而不是一次性渲染所有元素`。当用户滚动时，它会动态地加载和卸载DOM元素，从而显著提高性能。

2. 分页加载（Pagination）：

对于级联选择器，可以考虑分页加载数据。例如，当用户选择省份后，再加载对应省份的城市列表，而不是一次性加载所有城市。

3. 延迟加载（Lazy Loading）：

延迟加载是另一种技术，它只在需要时才加载数据。例如，当用户开始滚动到某个区域时，才开始加载该区域的数据。


4. 使用Web Workers：

Web Workers允许在后台线程中运行JavaScript，从而不会阻塞主线程。可以将数据处理逻辑（如数据转换、排序等）放在Web Worker中执行，避免阻塞UI渲染。

5. 缓存数据：

如果数据不经常变化，可以考虑缓存数据。这样，当用户再次访问相同的选项时，可以直接从缓存中获取，而不需要重新加载。

6. 减少渲染次数：

使用CSS的display: none或visibility: hidden来隐藏不需要显示的元素，而不是频繁地添加和删除DOM元素。


### 虚拟滚动的原理是什么？

在虚拟滚动中，`根据当前可视区域的高度，计算并渲染显示的数据量，而对超出视口之外的数据则不进行渲染`。

这样可以确保每一次滚动渲染的DOM元素都是可控的，不会一次性渲染过多数据，也不会发生数据堆积的问题。这种技术有助于提高数据处理的效率和性能，特别是在处理大量数据时，可以显著提升用户体验。



### 前端怎么处理菜单权限校验？

1. 前端拿到用户身份，判断用户权限；
2. 遍历路由菜单数组，根据用户权限，生成一个动态菜单列表；权限校验从高到低：超管 》管理员 》 普通
3. 同时在路由守卫那里也添加权限校验判断



### vuex的源码实现原理？

在源码层面，Vuex 利用 Vue 的响应式系统（Observer、Dep、Watcher）来监听和触发状态的改变。Vuex 的状态管理实际上是一个 Vue 实例，它的 state 是一个响应式对象。当调用 mutation 方法时，Vue 的响应式系统会自动更新所有依赖于这个状态的组件。

- `状态管理`：Vuex 使用单一状态树，用一个对象就包含了全部的应用层级状态。这使得我们能够直接地定位任一特定的状态片段，也能在调试的过程中进行高效的状态快照管理。

- `状态改变`：Vuex 的状态改变的唯一途径就是显式地提交 (commit) mutation。这个规则确保了视图和网络请求都不能直接改变状态，这使得我们可以方便地跟踪每一个状态的变化，从而让我们能够实现一些工具帮助我们更好地了解我们的应用

- `模块`：由于使用单一状态树，应用的所有状态会集中到一个比较大的对象中。当应用变得非常复杂时，store 对象就有可能变得相当臃肿。为了解决这个问题，Vuex 允许我们将 store 分割成模块（modules）。每个模块拥有自己的 state、mutation、action、getter、甚至是嵌套子模块——从上至下进行同样方式的分割。

- `插件`：Vuex 允许你使用 store.plugin 方法安装插件，以扩展 Vuex 的功能


Vuex的源码主要做了什么：

1. 首先肯定是要定义一个install方法，因为我们是通过Vue.use(Vuex)进行安装，那这个方法具体都做了什么呢？我们回顾下源码发现：

先是初始化全局变量Vue,之后获取这个传入的Vue的$options参数里的store，最后是通过一层层往上查询的方式实现所有组件都挂载了store，这样我们就能在所有组件中通过this.$store获取生成的Store对象了；

2. 之后就是Store实例的初始化：首先是初始化一些内部变量，然后生成ModuleCollection实例_module；之后就是调用installModule方法，通过递归注册所有模块；

3. 之后就是调用resetStoreVM方法注册vm：对所有已经注册的getters、state设置代理监听，通过给store生成一个Vue实例_vm，来实现数据变化的动态更新，其实说白了还是用了Vue的双向数据绑定来实现数据的响应更新




### AngularJS中的脏检查原理？

AngularJS中的脏检查（Dirty Checking）是一种机制，它基于AngularJS的数据绑定和监控机制，实现了自动化的UI更新。脏检查机制的核心是digest循环，当AngularJS启动时，它会自动调用apply函数来开始脏检查循环。

apply函数会检查当前scope对象中所有绑定到属性的watcher函数，如果属性的值发生了变化，它会执行watcher函数，以便更新UI界面。这个过程`会递归地检查所有的watch表达式，直到model值不再发生变化`，此时浏览器会重新渲染DOM来体现model的改变。

需要注意的是，AngularJS并不是周期性触发脏检查，`只有当view中事件、ajax请求或者timeout延迟事件等触发时，才会开始脏检查`。因此，脏检查机制能够确保只有在数据实际发生变化时才进行UI更新，提高了性能和效率。



### 大文件的分片上传和断点续传怎么做的？

- **分片上传：**

1. 将需要上传的大文件按照一定的分割规则，分割成相同大小的数据块。
2. 初始化一个分片上传任务，返回本次分片上传的唯一标识。
3. 按照一定的策略（串行或并行）发送各个分片数据块。


- **断点续传：**

1. 前端（客户端）需要根据固定大小对文件进行分片，请求后端（服务端）时要带上分片序号和大小。
2. 服务端创建conf文件用来记录分块位置，conf文件长度为总分片数，每上传一个分块即向conf文件中写入一个标识，那么没上传的位置就是默认的标识，已上传的就是另一标识（这步是实现断点续传和秒传的核心步骤）。
3. 服务器按照请求数据中给的分片序号和每片分块大小（分片大小是固定且一样的）算出开始位置，与读取到的文件片段数据，写入文件。
4. 当文件下载中断在续传时，判断小文件名称若存在则不存了，此时还需要判断文件若不是最后一个分片则大小为缓冲区固定大小，若没达到则证明小文件没传完需要重新传输。




- **git rebase  和 git merge 的区别？**

1. Git Merge：合并操作会创建一个新的合并提交（merge commit），将两个分支的历史记录合并在一起。这样会保留每个分支的提交历史，产生一个合并节点，它显示了两个分支的合并点；用 merge 拉取远程变更的结果是，每次你想获取项目的最新进展时，都会有一个多余的 merge 提交；
rebase 通常用于重写提交历史, 使用 rebase 可以使我们保持一个线性且更加整洁的提交历史；

2. Git Merge：合并操作不会改变提交历史，因此是一种相对安全的合并方式。Git Rebase：重新基于操作会重写提交历史，可能会造成团队协作时的混乱，特别是在公共分支上使用时

3. Git Merge：通常用于合并独立的开发分支或者在合并时不需要修改历史记录的情况。适合在公共分支上进行合并操作。Git Rebase：通常用于将一个分支的更改整合到另一个分支上，并且保持项目历史记录的整洁和线性。适合在私有分支上进行整理提交历史操作。



- `Promise.resolve()`: 创建一个 Promise 实例，将 Promise 实例设置为 resolve 状态，这个 Promise.resolve() 是同步的，且该 Promise 已经完成了



### 页面怎么做强制刷新？

`location.reload(true)`, `<meta http-equiv="refresh" content="0">`, `Ctrl + F5`